<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://liuhuipy.github.io</id>
    <title>nobuggeek</title>
    <updated>2020-06-10T09:33:36.295Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://liuhuipy.github.io"/>
    <link rel="self" href="https://liuhuipy.github.io/atom.xml"/>
    <subtitle>æ¸©æ•…è€ŒçŸ¥æ–°</subtitle>
    <logo>https://liuhuipy.github.io/images/avatar.png</logo>
    <icon>https://liuhuipy.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, nobuggeek</rights>
    <entry>
        <title type="html"><![CDATA[Kubernetesçš„ä»‹ç»ã€åŸºæœ¬æ¦‚å¿µå’Œé›†ç¾¤å®‰è£…éƒ¨ç½²]]></title>
        <id>https://liuhuipy.github.io/post/kubernetes-Introduction/</id>
        <link href="https://liuhuipy.github.io/post/kubernetes-Introduction/">
        </link>
        <updated>2020-06-09T03:17:39.000Z</updated>
        <summary type="html"><![CDATA[<p>Kubernetesç®€ä»‹ã€é›†ç¾¤éƒ¨ç½²ã€åŸºæœ¬æ¦‚å¿µ</p>
]]></summary>
        <content type="html"><![CDATA[<p>Kubernetesç®€ä»‹ã€é›†ç¾¤éƒ¨ç½²ã€åŸºæœ¬æ¦‚å¿µ</p>
<!-- more -->
<p>Kubernetesæ˜¯ä¸€ä¸ªå…¨æ–°çš„åŸºäºå®¹å™¨æŠ€æœ¯çš„åˆ†å¸ƒå¼æ¶æ„è§£å†³æ–¹æ¡ˆï¼Œæ˜¯è°·æ­Œåå‡ å¹´ä»¥æ¥å¤§è§„æ¨¡åº”ç”¨å®¹å™¨æŠ€æœ¯çš„ç»éªŒç§¯ç´¯å’Œå‡åçš„é‡è¦æˆæœã€‚Kubernetesæºè‡ªäºè°·æ­Œä¸€ä¸ªå«Borgçš„å†…éƒ¨å®¹å™¨ç®¡ç†ç³»ç»Ÿï¼ˆåæ¥è¿˜æœ‰ä¸€ä¸ªæ–°ç³»ç»Ÿå«Omegaï¼‰ï¼Œè°·æ­Œéƒ¨ç½²Borgç³»ç»Ÿå¯¹æ¥è‡ªäºæˆåƒä¸Šä¸‡ä¸ªåº”ç”¨ç¨‹åºæ‰€æäº¤çš„jobè¿›è¡Œæ¥æ”¶ã€è°ƒè¯•ã€å¯åŠ¨ã€åœæ­¢ã€é‡å¯å’Œç›‘æ§ï¼Œå®ƒåŸºäºå®¹å™¨æŠ€æœ¯ï¼Œç›®çš„æ˜¯å®ç°èµ„æºç®¡ç†çš„è‡ªåŠ¨åŒ–ï¼Œä»¥åŠè·¨å¤šä¸ªæ•°æ®ä¸­å¿ƒèµ„æºåˆ©ç”¨ç‡çš„æœ€å¤§åŒ–ã€‚è€Œæ¨ªç©ºå‡ºä¸–çš„Kubernetesé¡¹ç›®æ­£æ˜¯æå–äº†Borgæœ€ç²¾åçš„éƒ¨åˆ†ï¼Œä½¿å¼€å‘è€…èƒ½å¤Ÿæ›´ç®€å•ã€ç›´æ¥åœ°ç®¡ç†åº”ç”¨ã€‚</p>
<p>Kubernetesæ˜¯ä¸€ä¸ªå®Œå¤‡çš„åˆ†å¸ƒå¼ç³»ç»Ÿæ”¯æ’‘å¹³å°ã€‚Kuberneteså…·æœ‰å®Œå¤‡çš„é›†ç¾¤ç®¡ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¤šå±‚æ¬¡çš„å®‰å…¨é˜²æŠ¤å’Œå‡†å…¥æœºåˆ¶ã€å¤šç§Ÿæˆ·åº”ç”¨æ”¯æ’‘èƒ½åŠ›ã€é€æ˜çš„æœåŠ¡æ³¨å†Œå’ŒæœåŠ¡å‘ç°æœºåˆ¶ã€æ™ºèƒ½çš„è´Ÿè½½å‡è¡¡å™¨ã€å¼ºå¤§çš„æ•…éšœå‘ç°å’Œè‡ªæˆ‘ä¿®å¤èƒ½åŠ›ã€æœåŠ¡æ»šåŠ¨å‡çº§å’Œåœ¨çº¿æ‰©å®¹èƒ½åŠ›ã€å¯æ‰©å±•çš„èµ„æºè‡ªåŠ¨è°ƒåº¦æœºåˆ¶ï¼Œä»¥åŠå¤šç²’åº¦çš„èµ„æºé…é¢ç®¡ç†èƒ½åŠ›ã€‚</p>
<h2 id="kubernetesçš„æ ¸å¿ƒåŠŸèƒ½">ğŸ€Kubernetesçš„æ ¸å¿ƒåŠŸèƒ½ï¼š</h2>
<ul>
<li>å¸®åŠ©å¼€å‘è€…èšç„¦æ ¸å¿ƒåº”ç”¨åŠŸèƒ½ï¼šKuberneteså¯ä»¥è¢«çœ‹ä½œä¸€ä¸ªæ“ä½œç³»ç»Ÿï¼Œåº”ç”¨æ‰€éœ€è¦çš„åŸºç¡€è®¾æ–½ä¸ç”¨å¼€å‘è€…æ¥æ‹…å¿ƒã€‚ä»–ä»¬ç°åœ¨ä¾èµ–äºKubernetesæ¥æä¾›è¿™äº›æœåŠ¡ï¼ŒåŒ…æ‹¬æœåŠ¡å‘ç°ã€æ‰©å®¹ã€è´Ÿè½½å‡è¡¡ã€è‡ªæ¢å¤ã€‚åº”ç”¨ç¨‹åºå¼€å‘è€…å› æ­¤èƒ½é›†ä¸­å®ç°åº”ç”¨æœ¬èº«çš„åŠŸèƒ½è€Œä¸ç”¨èŠ±æ—¶é—´åœ¨é›†æˆåº”ç”¨å’ŒåŸºç¡€è®¾æ–½ä¸Šã€‚</li>
<li>å¸®åŠ©è¿ç»´å›¢é˜Ÿè·å–æ›´é«˜çš„æœåŠ¡å™¨èµ„æºåˆ©ç”¨ç‡ï¼šKubernetesè‡ªåŠ¨è°ƒåº¦åº”ç”¨å®¹å™¨åˆ°é›†ç¾¤çš„æŸä¸ªèŠ‚ç‚¹ä¸Šï¼ŒKubernetesèƒ½åœ¨ä»»ä½•æ—¶é—´è¿ç§»åº”ç”¨å¹¶é€šè¿‡æ··åˆå’ŒåŒ¹é…åº”ç”¨æ¥è·å¾—æ¯”è¿ç»´æ‰‹åŠ¨è°ƒåº¦é«˜å¾ˆå¤šçš„èµ„æºåˆ©ç”¨ç‡ã€‚</li>
</ul>
<h2 id="kuberneteså®‰è£…ä¸é…ç½®">ğŸŒ³Kuberneteså®‰è£…ä¸é…ç½®</h2>
<h3 id="kubernetesé›†ç¾¤æ­å»ºæ–¹å¼">Kubernetesé›†ç¾¤æ­å»ºæ–¹å¼ï¼š</h3>
<ul>
<li>kubeadmï¼šKubernetes 1.4å¼€å§‹æ–°å¢çš„ç‰¹æ€§ï¼Œç”¨äºå¿«é€Ÿæ­å»ºKubernetesé›†ç¾¤ï¼›</li>
<li>minikubeï¼šå¿«é€Ÿæ­å»ºä¸€ä¸ªè¿è¡Œåœ¨æœ¬åœ°çš„å•èŠ‚ç‚¹çš„Kubernetesï¼›</li>
<li>äºŒè¿›åˆ¶å®‰è£…ï¼šä¸‹è½½Kubernetesæ‰€éœ€ç»„ä»¶çš„äºŒè¿›åˆ¶åŒ…ï¼Œä¸€æ­¥æ­¥å®‰è£…ã€‚</li>
</ul>
<p>ğŸä¸ºäº†æ›´å¥½çš„äº†è§£ã€ç†Ÿæ‚‰Kubernetesé›†ç¾¤çš„å„ä¸ªç»„ä»¶ï¼Œæœ¬æ–‡é‡‡ç”¨äºŒè¿›åˆ¶éƒ¨ç½²Kubernetesé›†ç¾¤ã€‚</p>
<h3 id="é›†ç¾¤è¯¦æƒ…">é›†ç¾¤è¯¦æƒ…</h3>
<ul>
<li>OSï¼šCentos Linux version 3.10.0-1127.el7.x86_64</li>
<li>Kubernetes 1.18.0</li>
<li>Dockerï¼šdocker-1.13.1-161.git64e9980.el7_8.x86_64</li>
<li>Etcd 3.1.5</li>
<li>Flannel 0.7.1</li>
<li>TLSè®¤è¯é€šä¿¡</li>
<li>RBACæˆæƒ</li>
<li>kubelet TLS Bootstrapping</li>
<li>kubednsã€dashboardã€heapsterï¼ˆinfluxdbã€grafanaï¼‰ã€EFKï¼ˆelasticsearchã€fluentdã€kibanaï¼‰é›†ç¾¤æ’ä»¶</li>
<li>ç§æœ‰åŒ–dockeré•œåƒä»“åº“harbor</li>
</ul>
<h3 id="ç¯å¢ƒè¯´æ˜">ç¯å¢ƒè¯´æ˜</h3>
<ul>
<li>é•œåƒä»“åº“ï¼šIPï¼š192.168.143.133ï¼ŒDomainï¼šharbor.liuhui.io</li>
<li>Etcdï¼š192.168.143.128ï¼Œ192.168.143.129ï¼Œ192.168.143.130é«˜å¯ç”¨etcdé›†ç¾¤</li>
<li>Masterï¼š192.168.143.128ï¼Œ192.168.143.129ï¼Œ192.168.143.130ä¸‰å°ï¼Œé«˜å¯ç”¨</li>
<li>Nodeï¼š192.168.143.128ï¼Œ192.168.143.129ï¼Œ192.168.143.130ï¼Œ192.168.143.131ï¼Œ192.168.143.122äº”å°NodeèŠ‚ç‚¹</li>
</ul>
<h3 id="å®‰è£…å‰å‡†å¤‡">å®‰è£…å‰å‡†å¤‡</h3>
<ul>
<li>ç¯å¢ƒè¯´æ˜</li>
<li>æ¯ä¸ªèŠ‚ç‚¹ä¸Šå®‰è£…Docker</li>
</ul>
<pre><code>yum install docker -y
cd /etc/docker
vi daemon.json
{
  &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]
}
systemctl daemon-reload
systemctl start docker
</code></pre>
<ul>
<li>å…³é—­æ‰€æœ‰èŠ‚ç‚¹çš„Selinux</li>
</ul>
<pre><code>vi /etc/selinux/configè¿›å…¥æ–‡ä»¶ä¸­ä¿®æ”¹é…ç½®SELINUX=disabledï¼Œç„¶åé‡å¯æœåŠ¡å™¨ã€‚
</code></pre>
<ul>
<li>å‡†å¤‡harborç§æœ‰é•œåƒä»“åº“</li>
</ul>
<h3 id="åˆ›å»ºtlsè¯ä¹¦å’Œç§˜é’¥">åˆ›å»ºTLSè¯ä¹¦å’Œç§˜é’¥</h3>
<p>æ‰€æœ‰æ“ä½œéƒ½åœ¨MasterèŠ‚ç‚¹192.168.143.128ä¸Šæ‰§è¡Œï¼Œè¯ä¹¦ç”Ÿæˆåæ‹·è´åˆ°/etc/kubernetesç›®å½•ä¸‹å¹¶æ‹·è´åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šçš„åŒæ ·ç›®å½•ã€‚</p>
<h4 id="ç”Ÿæˆçš„caè¯ä¹¦å’Œç§˜é’¥æ–‡ä»¶å¦‚ä¸‹">ç”Ÿæˆçš„CAè¯ä¹¦å’Œç§˜é’¥æ–‡ä»¶å¦‚ä¸‹ï¼š</h4>
<ul>
<li>ca-key.pm</li>
<li>ca.pem</li>
<li>kubernetes-key.pem</li>
<li>kubernetes.pem</li>
<li>kube-proxy.pem</li>
<li>kube-proxy-key.pem</li>
<li>admin.pem</li>
<li>admin-key.pem</li>
</ul>
<h4 id="ä½¿ç”¨è¯ä¹¦çš„ç»„ä»¶å¦‚ä¸‹">ä½¿ç”¨è¯ä¹¦çš„ç»„ä»¶å¦‚ä¸‹ï¼š</h4>
<ul>
<li>etcdï¼šä½¿ç”¨ca.pemã€kubernetes-key.pemã€kubernetes.pemï¼›</li>
<li>kube-apiserverï¼šä½¿ç”¨ca.pemã€kubernetes-key.pemã€kubernetes.pemï¼›</li>
<li>kubeletï¼šä½¿ç”¨ca.pemï¼›</li>
<li>kube-proxyï¼šä½¿ç”¨ca.pemã€kube-proxy-key.pemã€kube-proxy.pemï¼›</li>
<li>kubectlï¼šä½¿ç”¨ca.pemã€admin-key.pemã€adminã€pemï¼›ã€</li>
<li>kube-controller-managerï¼šä½¿ç”¨ca-key.pemã€caã€pemã€‚</li>
</ul>
<h4 id="å®‰è£…cfssl">å®‰è£…CFSSL</h4>
<p>æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p>
<pre><code>wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
chmod +x cfssl_linux-amd64
mv cfssl_linux-amd64 /usr/local/bin/cfssl

wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
chmod +x cfssljson_linux-amd64
mv cfssljson_linux-amd64 /usr/local/bin/cfssljson

wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
chmod +x cfssl-certinfo_linux-amd64
mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo
</code></pre>
<h4 id="åˆ›å»ºcacertificate-authority">åˆ›å»ºCAï¼ˆCertificate Authorityï¼‰</h4>
<p>åˆ›å»ºCAé…ç½®æ–‡ä»¶ï¼š</p>
<pre><code>mkdir /root/ssl
cd /root/ssl
cfssl print-defaults config &gt; config.json
cfssl print-defaults csr &gt; csr.json

cat &gt; ca-config.json &lt;&lt;EOF
{
  &quot;signing&quot;: {
    &quot;default&quot;: {
      &quot;expiry&quot;: &quot;87600h&quot;
    },
    &quot;profiles&quot;: {
      &quot;kubernetes&quot;: {
        &quot;usages&quot;: [
            &quot;signing&quot;,
            &quot;key encipherment&quot;,
            &quot;server auth&quot;,
            &quot;client auth&quot;
        ],
        &quot;expiry&quot;: &quot;87600h&quot;
      }
    }
  }
}
EOF
</code></pre>
<ul>
<li>ca-config.jsonï¼šå¯ä»¥å®šä¹‰å¤šä¸ªprofilesï¼Œåˆ†åˆ«æŒ‡å®šä¸åŒçš„è¿‡æœŸæ—¶é—´ã€ä½¿ç”¨åœºæ™¯ç­‰å‚æ•°ï¼›åç»­åœ¨ç­¾åè¯ä¹¦æ—¶ä½¿ç”¨æŸä¸ªprofileï¼›</li>
<li>signingï¼šè¡¨ç¤ºè¯¥è¯ä¹¦å¯ç”¨äºç­¾åå…¶å®ƒè¯ä¹¦ï¼Œç”Ÿæˆçš„ca.pemè¯ä¹¦ä¸­CA=TRUEï¼›</li>
<li>server authï¼šè¡¨ç¤ºclientå¯ä»¥ç”¨è¯¥CAå¯¹serveræä¾›çš„è¯ä¹¦è¿›è¡ŒéªŒè¯ï¼›</li>
<li>client authï¼šè¡¨ç¤ºserverå¯ä»¥ç”¨è¯¥CAå¯¹clientæä¾›çš„è¯ä¹¦è¿›è¡ŒéªŒè¯ã€‚</li>
</ul>
<p>åˆ›å»ºCAè¯ä¹¦ç­¾åè¯·æ±‚ï¼š</p>
<pre><code>cat &gt; ca-csr.json &lt;&lt;EOF
{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ],
    &quot;ca&quot;: {
       &quot;expiry&quot;: &quot;87600h&quot;
    }
}
EOF
</code></pre>
<ul>
<li>CNï¼šCommon Nameï¼Œkube-apiserverä»è¯ä¹¦ä¸­æå–è¯¥å­—æ®µä½œä¸ºè¯·æ±‚çš„ç”¨æˆ·åï¼ˆUser Nameï¼‰ï¼›</li>
<li>Oï¼šOrganizationï¼Œkube-apiserverä»è¯ä¹¦ä¸­æå–è¯¥å­—æ®µä½œä¸ºè¯·æ±‚ç”¨æˆ·æ‰€å±çš„ç»„ï¼ˆGroupï¼‰ï¼›</li>
</ul>
<p>ç”ŸæˆCAè¯ä¹¦å’Œç§é’¥ï¼š</p>
<pre><code># cfssl gencert -initca ca-csr.json | cfssljson -bare ca
# ls ca*
ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem
</code></pre>
<h4 id="åˆ›å»ºkubernetesè¯ä¹¦">åˆ›å»ºKubernetesè¯ä¹¦</h4>
<p>åˆ›å»ºkubernetesè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶kubernetes-csr.jsonï¼š</p>
<pre><code>{
  &quot;CN&quot;: &quot;kubernetes&quot;,
  &quot;hosts&quot;: [
    &quot;127.0.0.1&quot;,
    &quot;172.20.0.128&quot;,
    &quot;192.168.143.128&quot;,
    &quot;192.168.143.129&quot;,
    &quot;192.168.143.130&quot;,
    &quot;192.168.143.131&quot;,
    &quot;192.168.143.132&quot;,
    &quot;10.254.0.1&quot;,
    &quot;kubernetes&quot;,
    &quot;kubernetes.default&quot;,
    &quot;kubernetes.default.svc&quot;,
    &quot;kubernetes.default.svc.cluster&quot;,
    &quot;kubernetes.default.svc.cluster.local&quot;
  ],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
</code></pre>
<ul>
<li>å¦‚æœhostså­—æ®µä¸ä¸ºç©ºåˆ™éœ€è¦æŒ‡å®šæˆæƒä½¿ç”¨è¯¥è¯ä¹¦çš„IPåœ°å€æˆ–è€…åŸŸååˆ—è¡¨ï¼Œç”±äºè¯¥è¯ä¹¦åç»­è¢«etcdé›†ç¾¤å’Œkubernetes masteré›†ç¾¤ä½¿ç”¨ï¼Œæ‰€ä»¥ä¸Šé¢åˆ†åˆ«æŒ‡å®šäº†etcdé›†ç¾¤ã€kubernetes masteré›†ç¾¤å’ŒKubernetes NodeèŠ‚ç‚¹çš„IPåœ°å€ï¼›</li>
</ul>
<p>ç”ŸæˆKubernetesè¯ä¹¦å’Œç§é’¥ï¼š</p>
<pre><code># cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes
# ls kubernetes*
kubernetes.csr  kubernetes-csr.json  kubernetes-key.pem  kubernetes.pem
</code></pre>
<h4 id="åˆ›å»ºadminè¯ä¹¦">åˆ›å»ºadminè¯ä¹¦</h4>
<p>åˆ›å»ºadminè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶admin-csr.jsonï¼š</p>
<pre><code>{
  &quot;CN&quot;: &quot;admin&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;system:masters&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
</code></pre>
<ul>
<li>åç»­kube-apiserverä½¿ç”¨RBACå¯¹å®¢æˆ·ç«¯ï¼ˆå¦‚kubeletã€kube-proxyã€Podï¼‰è¯·æ±‚è¿›è¡Œæˆæƒï¼›</li>
<li>kube-apiserveré¢„å®šä¹‰äº†ä¸€äº›RBACçš„RoleBindingsï¼Œå¦‚cluster-adminå°†Group system:mastersä¸Role cluster-adminç»‘å®šï¼Œè¯¥Roleæˆäºˆäº†è°ƒç”¨kube-apiserverçš„æ‰€æœ‰APIçš„æƒé™ï¼›</li>
<li>OæŒ‡å®šè¯¥è¯ä¹¦çš„Groupä¸ºsystem:mastersï¼Œkubeletä½¿ç”¨è¯¥è¯ä¹¦è®¿é—®kube-apiserveræ—¶ï¼Œç”±äºè¯ä¹¦è¢«CAç­¾åï¼Œæ‰€ä»¥è®¤è¯é€šè¿‡ï¼ŒåŒæ—¶ç”±äºè¯ä¹¦ç”¨æˆ·ç»„ä¸ºç»è¿‡é¢„æˆæƒçš„system:mastersï¼Œæ‰€ä»¥è¢«æˆæƒè®¿é—®æ‰€æœ‰APIçš„æƒé™ã€‚</li>
</ul>
<p>ç”Ÿæˆadminè¯ä¹¦å’Œç§é’¥ï¼š</p>
<pre><code># cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin
# ls admin*
admin.csr  admin-csr.json  admin-key.pem  admin.pem
</code></pre>
<h4 id="åˆ›å»ºkube-proxyè¯ä¹¦">åˆ›å»ºkube-proxyè¯ä¹¦</h4>
<p>åˆ›å»ºkube-proxyè¯ä¹¦ç­¾åè¯·æ±‚æ–‡ä»¶kube-proxy-csr.jsonï¼š</p>
<pre><code>{
  &quot;CN&quot;: &quot;system:kube-proxy&quot;,
  &quot;hosts&quot;: [],
  &quot;key&quot;: {
    &quot;algo&quot;: &quot;rsa&quot;,
    &quot;size&quot;: 2048
  },
  &quot;names&quot;: [
    {
      &quot;C&quot;: &quot;CN&quot;,
      &quot;ST&quot;: &quot;BeiJing&quot;,
      &quot;L&quot;: &quot;BeiJing&quot;,
      &quot;O&quot;: &quot;k8s&quot;,
      &quot;OU&quot;: &quot;System&quot;
    }
  ]
}
</code></pre>
<ul>
<li>CNæŒ‡å®šè¯¥è¯ä¹¦çš„Userä¸ºsystem:kube-proxyï¼›</li>
<li>kube-apiserveré¢„å®šä¹‰çš„RoleBinding system:node-proxierå°†User system:kube-proxyä¸Role system:node-proxierç»‘å®šï¼Œè¯¥Roleæˆäºˆäº†è°ƒç”¨kube-apiserver Proxyç›¸å…³APIçš„æƒé™ã€‚</li>
</ul>
<p>ç”Ÿæˆkube-proxyå®¢æˆ·ç«¯è¯ä¹¦å’Œç§é’¥ï¼š</p>
<pre><code># cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes  kube-proxy-csr.json | cfssljson -bare kube-proxy
# ls kube-proxy*
kube-proxy.csr  kube-proxy-csr.json  kube-proxy-key.pem  kube-proxy.pem
</code></pre>
<p>ä½¿ç”¨opensslå‘½ä»¤æ ¡éªŒè¯ä¹¦ï¼š</p>
<pre><code>openssl x509  -noout -text -in  kubernetes.pem
</code></pre>
<ul>
<li>ç¡®è®¤Issuerå­—æ®µçš„å†…å®¹å’Œca-csr.jsonä¸€è‡´ï¼›</li>
<li>ç¡®è®¤Subjectå­—æ®µçš„å†…å®¹å’Œkubernetes-csr.jsonä¸€è‡´ï¼›</li>
<li>ç¡®è®¤ X509v3 Subject Alternative Name å­—æ®µçš„å†…å®¹å’Œ kubernetes-csr.json ä¸€è‡´ï¼›</li>
<li>ç¡®è®¤ X509v3 Key Usageã€Extended Key Usage å­—æ®µçš„å†…å®¹å’Œ ca-config.json ä¸­ kubernetes profile ä¸€è‡´ã€‚</li>
</ul>
<h4 id="åˆ†å‘è¯ä¹¦">åˆ†å‘è¯ä¹¦</h4>
<p>å°†ç”Ÿæˆçš„è¯ä¹¦å’Œç§˜é’¥æ–‡ä»¶æ‹·è´åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„/etc/kubernetes/sslï¼ˆå…ˆç»™æ¯ä¸ªèŠ‚ç‚¹mkdiråˆ›å»ºè¯¥ç›®å½•ï¼‰ç›®å½•ä¸‹ï¼š</p>
<pre><code>mkdir -p /etc/kubernetes/ssl
cp *.pem /etc/kubernetes/ssl
scp *.pem root@192.168.143.129:/etc/kubernetes/ssl
scp *.pem root@192.168.143.130:/etc/kubernetes/ssl
scp *.pem root@192.168.143.131:/etc/kubernetes/ssl
scp *.pem root@192.168.143.132:/etc/kubernetes/ssl
</code></pre>
<h3 id="å®‰è£…kubectlä¸åˆ›å»ºkubeconfigæ–‡ä»¶">å®‰è£…kubectlä¸åˆ›å»ºkubeconfigæ–‡ä»¶</h3>
<h4 id="ä¸‹è½½kubectl">ä¸‹è½½kubectl</h4>
<pre><code>wget https://dl.k8s.io/v1.6.0/kubernetes-client-linux-amd64.tar.gz
tar -xzvf kubernetes-client-linux-amd64.tar.gz
cp kubernetes/client/bin/kube* /usr/bin/
chmod a+x /usr/bin/kube*
</code></pre>
<h4 id="åˆ›å»ºkubectl-kubeconfigæ–‡ä»¶">åˆ›å»ºkubectl kubeconfigæ–‡ä»¶</h4>
<pre><code>export KUBE_APISERVER=&quot;https://192.168.143.128:6443&quot;
# è®¾ç½®é›†ç¾¤å‚æ•°
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER}
# è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•°
kubectl config set-credentials admin \
  --client-certificate=/etc/kubernetes/ssl/admin.pem \
  --embed-certs=true \
  --client-key=/etc/kubernetes/ssl/admin-key.pem
# è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•°
kubectl config set-context kubernetes \
  --cluster=kubernetes \
  --user=admin
# è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡
kubectl config use-context kubernetes
</code></pre>
<h4 id="åˆ›å»ºtls-bootstrapping-token">åˆ›å»ºTLS Bootstrapping Token</h4>
<p>ç”Ÿæˆtoken auth fileï¼ŒTokenå¯ä»¥æ˜¯ä»»æ„çš„åŒ…å«128 bitçš„å­—ç¬¦ä¸²ï¼Œå¯ä»¥ä½¿ç”¨å®‰å…¨çš„éšæœºæ•°ç”Ÿæˆå™¨ç”Ÿæˆï¼š</p>
<pre><code>export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ')
cat &gt; token.csv &lt;&lt;EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;
EOF
cp token.csv /etc/kubernetes/
</code></pre>
<h4 id="åˆ›å»ºkubelet-bootstrapping-kubeconfigæ–‡ä»¶">åˆ›å»ºkubelet bootstrapping kubeconfigæ–‡ä»¶</h4>
<pre><code>cd /etc/kubernetes
export KUBE_APISERVER=&quot;https://192.168.143.128:6443&quot;

# è®¾ç½®é›†ç¾¤å‚æ•°
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•°
kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•°
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig
</code></pre>
<h4 id="åˆ›å»ºkube-proxy-kubeconfigæ–‡ä»¶">åˆ›å»ºkube-proxy kubeconfigæ–‡ä»¶</h4>
<pre><code>export KUBE_APISERVER=&quot;https://192.168.143.128:6443&quot;
# è®¾ç½®é›†ç¾¤å‚æ•°
kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig
# è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•°
kubectl config set-credentials kube-proxy \
  --client-certificate=/etc/kubernetes/ssl/kube-proxy.pem \
  --client-key=/etc/kubernetes/ssl/kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig
# è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•°
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig
# è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡
kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
</code></pre>
<h4 id="åˆ†å‘kubeconfigæ–‡ä»¶">åˆ†å‘kubeconfigæ–‡ä»¶</h4>
<p>å°†ä¸¤ä¸ªkubeconfigæ–‡ä»¶åˆ†å‘åˆ°æ‰€æœ‰NodeèŠ‚ç‚¹çš„/etc/kubernetes/ç›®å½•ä¸‹ï¼š</p>
<pre><code>scp bootstrap.kubeconfig kube-proxy.kubeconfig root@192.168.143.129:/etc/kubernetes/
scp bootstrap.kubeconfig kube-proxy.kubeconfig root@192.168.143.130:/etc/kubernetes/
scp bootstrap.kubeconfig kube-proxy.kubeconfig root@192.168.143.131:/etc/kubernetes/
scp bootstrap.kubeconfig kube-proxy.kubeconfig root@192.168.143.132:/etc/kubernetes/
</code></pre>
<h3 id="åˆ›å»ºé«˜å¯ç”¨etcdé›†ç¾¤">åˆ›å»ºé«˜å¯ç”¨etcdé›†ç¾¤</h3>
<p>kubernetesç³»ç»Ÿä½¿ç”¨etcdå­˜å‚¨æ‰€æœ‰æ•°æ®ï¼Œéƒ¨ç½²ä¸‰ä¸ªèŠ‚ç‚¹é«˜å¯ç”¨etcdé›†ç¾¤ï¼Œå¤ç”¨kubernetes masterçš„èŠ‚ç‚¹ï¼š</p>
<ul>
<li>192.168.143.128</li>
<li>192.168.143.129</li>
<li>192.168.143.130</li>
</ul>
<h4 id="tlsè®¤è¯æ–‡ä»¶">TLSè®¤è¯æ–‡ä»¶</h4>
<p>è¿™é‡Œå¤ç”¨kubernetes masteråˆ›å»ºçš„kubernetesè¯ä¹¦</p>
<pre><code>scp ca.pem kubernetes-key.pem kubernetes.pem root@192.168.143.129:/etc/kubernetes/ssl
scp ca.pem kubernetes-key.pem kubernetes.pem root@192.168.143.130:/etc/kubernetes/ssl
</code></pre>
<h4 id="å®‰è£…etcd">å®‰è£…etcd</h4>
<p>ä¸‰ä¸ªèŠ‚ç‚¹éƒ½éœ€è¦ä»¥ä¸‹æ“ä½œã€‚<br>
ä¸‹è½½äºŒè¿›åˆ¶æ–‡ä»¶ï¼š</p>
<pre><code>wget https://github.com/coreos/etcd/releases/download/v3.1.5/etcd-v3.1.5-linux-amd64.tar.gz
tar -xvf etcd-v3.1.5-linux-amd64.tar.gz
mv etcd-v3.1.5-linux-amd64/etcd* /usr/local/bin
</code></pre>
<p>åœ¨/usr/lib/systemd/system/ç›®å½•ä¸‹åˆ›å»ºetcdçš„systemd unitæ–‡ä»¶etcd.serviceï¼š</p>
<pre><code>[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target
Documentation=https://github.com/coreos

[Service]
Type=notify
WorkingDirectory=/var/lib/etcd/
EnvironmentFile=-/etc/etcd/etcd.conf
ExecStart=/usr/local/bin/etcd \
  --name ${ETCD_NAME} \
  --cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --peer-cert-file=/etc/kubernetes/ssl/kubernetes.pem \
  --peer-key-file=/etc/kubernetes/ssl/kubernetes-key.pem \
  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \
  --initial-advertise-peer-urls ${ETCD_INITIAL_ADVERTISE_PEER_URLS} \
  --listen-peer-urls ${ETCD_LISTEN_PEER_URLS} \
  --listen-client-urls ${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \
  --advertise-client-urls ${ETCD_ADVERTISE_CLIENT_URLS} \
  --initial-cluster-token ${ETCD_INITIAL_CLUSTER_TOKEN} \
  --initial-cluster infra1=https://192.168.143.128:2380,infra2=https://192.168.143.129:2380,infra3=https://192.168.143.130:2380 \
  --initial-cluster-state new \
  --data-dir=${ETCD_DATA_DIR}
Restart=on-failure
RestartSec=5
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre>
<ul>
<li>æŒ‡å®šetcdçš„å·¥ä½œç›®å½•ä¸º/var/lib/etcdï¼Œæ•°æ®ç›®å½•ä¸º/var/lib/etcdï¼Œå¯åŠ¨æœåŠ¡å‰å¾—åˆ›å»ºè¯¥ç›®å½•ï¼›</li>
<li>ä¸ºäº†ä¿è¯é€šä¿¡å®‰å…¨ï¼Œéœ€è¦æŒ‡å®šetcdçš„å…¬ç§é’¥ï¼ˆcert-fileå’Œkey-fileï¼‰ã€Peersé€šä¿¡çš„å…¬ç§é’¥å’ŒCAè¯ä¹¦ï¼ˆpeer-cert-fileã€peer-key-fileã€peer=trusted-ca-fileï¼‰ã€å®¢æˆ·ç«¯çš„CAè¯ä¹¦ï¼ˆtrusted-ca-fileï¼‰ï¼›</li>
<li>åˆ›å»ºkubernetes.pemè¯ä¹¦æ—¶ä½¿ç”¨çš„kubernetes-csr.jsonæ–‡ä»¶çš„hostså­—æ®µåŒ…å«æ‰€æœ‰etcdèŠ‚ç‚¹çš„IPï¼Œå¦åˆ™è¯ä¹¦æ ¡éªŒä¼šå‡ºé”™ï¼›</li>
<li>--initial-cluster-stateå€¼ä¸ºnewæ—¶ï¼Œ--nameçš„å‚æ•°å€¼å¿…é¡»ä½äº--initial-clusteråˆ—è¡¨ä¸­ã€‚</li>
</ul>
<p>ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶/etc/etcd/etcd.confï¼ˆè¿™é‡Œæ³¨æ„æ¯ä¸ªetcdèŠ‚ç‚¹ETCD_NAMEå’ŒIPè¦è¿›è¡Œæ›´æ”¹ï¼‰ï¼š</p>
<pre><code># [member]
ETCD_NAME=infra1
ETCD_DATA_DIR=&quot;/var/lib/etcd&quot;
ETCD_LISTEN_PEER_URLS=&quot;https://192.168.143.128:2380&quot;
ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.143.128:2379&quot;

#[cluster]
ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.143.128:2380&quot;
ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot;
ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.143.128:2379&quot;
</code></pre>
<h4 id="å¯åŠ¨etcdæœåŠ¡">å¯åŠ¨etcdæœåŠ¡</h4>
<pre><code>systemctl daemon-reload
systemctl enable etcd
systemctl start etcd
</code></pre>
<p>ä¸ºäº†ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹é˜²ç«å¢™å¼€æ”¾äº†2379ã€2380ç«¯å£ï¼š</p>
<pre><code>firewall-cmd --zone=public --add-port=2380/tcp --permanent
firewall-cmd --zone=public --add-port=2379/tcp --permanent
firewall-cmd --reload
</code></pre>
<h4 id="éªŒè¯etcdæœåŠ¡">éªŒè¯etcdæœåŠ¡</h4>
<p>åœ¨ä»»æ„etcdèŠ‚ç‚¹ä¸Šæ‰§è¡Œï¼š</p>
<pre><code># etcdctl   --ca-file=/etc/kubernetes/ssl/ca.pem   --cert-file=/etc/kubernetes/ssl/kubernetes.pem   --key-file=/etc/kubernetes/ssl/kubernetes-key.pem   cluster-health

2020-06-10 02:04:18.318845 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated
2020-06-10 02:04:18.319487 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated
member 3624da61eeb2a34b is healthy: got healthy result from https://192.168.143.129:2379
member 83f50994fc838c06 is healthy: got healthy result from https://192.168.143.128:2379
member c507e67572829987 is healthy: got healthy result from https://192.168.143.130:2379
cluster is healthy
</code></pre>
<h3 id="éƒ¨ç½²masterèŠ‚ç‚¹">éƒ¨ç½²masterèŠ‚ç‚¹</h3>
<p>Kubernetes masterèŠ‚ç‚¹åŒ…å«çš„ç»„ä»¶ï¼š</p>
<ul>
<li>kube-apiserver</li>
<li>kube-scheduler</li>
<li>kube-controller-manager</li>
</ul>
<h4 id="ä¸‹è½½å¯¹åº”çš„kubernetesç‰ˆæœ¬">ä¸‹è½½å¯¹åº”çš„Kubernetesç‰ˆæœ¬</h4>
<pre><code>wget https://dl.k8s.io/v1.6.0/kubernetes-server-linux-amd64.tar.gz
tar -xzvf kubernetes-server-linux-amd64.tar.gz
cd kubernetes
tar -xzvf  kubernetes-src.tar.gz
cp -r server/bin/{kube-apiserver,kube-controller-manager,kube-scheduler,kubectl,kube-proxy,kubelet} /usr/local/bin/
</code></pre>
<h4 id="é…ç½®kube-apiserver-kube-scheduler-kube-controller-manageræ–‡ä»¶">é…ç½®kube-apiserverã€kube-schedulerã€kube-controller-manageræ–‡ä»¶</h4>
<p>æ·»åŠ /etc/kubernetes/configæ–‡ä»¶ï¼š</p>
<pre><code>###
# kubernetes system config
#
# The following values are used to configure various aspects of all
# kubernetes services, including
#
#   kube-apiserver.service
#   kube-controller-manager.service
#   kube-scheduler.service
#   kubelet.service
#   kube-proxy.service
# logging to stderr means we get it in the systemd journal
KUBE_LOGTOSTDERR=&quot;--logtostderr=true&quot;

# journal message level, 0 is debug
KUBE_LOG_LEVEL=&quot;--v=0&quot;

# Should this cluster be allowed to run privileged docker containers
KUBE_ALLOW_PRIV=&quot;--allow-privileged=true&quot;

# How the controller-manager, scheduler, and proxy find the apiserver
KUBE_MASTER=&quot;--master=http://192.168.143.128:8080&quot;
</code></pre>
<p>è¯¥é…ç½®æ–‡ä»¶åŒæ—¶è¢«kube-apiserverã€kube-schedulerã€kube-controller-managerã€kubeletã€kube-proxyä½¿ç”¨ã€‚</p>
<p>æ·»åŠ apiserveré…ç½®æ–‡ä»¶/etc/kubernetes/apiserverï¼š</p>
<pre><code>###
## kubernetes system config
##
## The following values are used to configure the kube-apiserver
##
#
## The address on the local server to listen to.
KUBE_API_ADDRESS=&quot;--advertise-address=192.168.143.128 --bind-address=192.168.143.128 --insecure-bind-address=192.168.143.128&quot;
#
## The port on the local server to listen on.
#KUBE_API_PORT=&quot;--port=8080&quot;
#
## Port minions listen on
#KUBELET_PORT=&quot;--kubelet-port=10250&quot;
#
## Comma separated list of nodes in the etcd cluster
KUBE_ETCD_SERVERS=&quot;--etcd-servers=https://192.168.143.128:2379,https://192.168.143.129:2379,https://192.168.143.130:2379&quot;
#
## Address range to use for services
KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;
#
## default admission control policies
KUBE_ADMISSION_CONTROL=&quot;--admission-control=ServiceAccount,NamespaceLifecycle,NamespaceExists,LimitRanger,ResourceQuota&quot;
#
## Add your own!
KUBE_API_ARGS=&quot;--authorization-mode=RBAC --runtime-config=rbac.authorization.k8s.io/v1beta1 --kubelet-https=true --experimental-bootstrap-token-auth --token-auth-file=/etc/kubernetes/token.csv --service-node-port-range=30000-32767 --tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem --tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem --client-ca-file=/etc/kubernetes/ssl/ca.pem --service-account-key-file=/etc/kubernetes/ssl/ca-key.pem --etcd-cafile=/etc/kubernetes/ssl/ca.pem --etcd-certfile=/etc/kubernetes/ssl/kubernetes.pem --etcd-keyfile=/etc/kubernetes/ssl/kubernetes-key.pem --enable-swagger-ui=true --apiserver-count=3 --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-path=/var/lib/audit.log --event-ttl=1h&quot;
</code></pre>
<p>æ·»åŠ scheduleré…ç½®æ–‡ä»¶/etc/kubernetes/schedulerï¼š</p>
<pre><code>###
# kubernetes scheduler config

# default config should be adequate

# Add your own!
KUBE_SCHEDULER_ARGS=&quot;--leader-elect=true --address=127.0.0.1&quot;
</code></pre>
<p>æ·»åŠ controller-manageré…ç½®æ–‡ä»¶/etc/kubernetes/controller-managerï¼š</p>
<pre><code>###
# The following values are used to configure the kubernetes controller-manager

# defaults from config and apiserver should be adequate

# Add your own!
KUBE_CONTROLLER_MANAGER_ARGS=&quot;--address=127.0.0.1 --service-cluster-ip-range=10.254.0.0/16 --cluster-name=kubernetes --cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem --cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem  --service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem --root-ca-file=/etc/kubernetes/ssl/ca.pem --leader-elect=true&quot;
</code></pre>
<h4 id="åˆ›å»ºkube-apiserver-serviceé…ç½®æ–‡ä»¶å’Œå¯åŠ¨kube-apiserver">åˆ›å»ºkube-apiserver serviceé…ç½®æ–‡ä»¶å’Œå¯åŠ¨kube-apiserver</h4>
<p>åˆ›å»ºkube-apiserverçš„serviceé…ç½®æ–‡ä»¶/usr/lib/systemd/system/kube-apiserver.serviceï¼š</p>
<pre><code>[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/GoogleCloudPlatform/kubernetes
After=network.target
After=etcd.service

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/apiserver
ExecStart=/usr/local/bin/kube-apiserver \
        $KUBE_LOGTOSTDERR \
        $KUBE_LOG_LEVEL \
        $KUBE_ETCD_SERVERS \
        $KUBE_API_ADDRESS \
        $KUBE_API_PORT \
        $KUBELET_PORT \
        $KUBE_ALLOW_PRIV \
        $KUBE_SERVICE_ADDRESSES \
        $KUBE_ADMISSION_CONTROL \
        $KUBE_API_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre>
<p>å¯åŠ¨kube-apiserver</p>
<pre><code>systemctl daemon-reload
systemctl enable kube-apiserver
systemctl start kube-apiserver
systemctl status kube-apiserver
</code></pre>
<h4 id="åˆ›å»ºkube-scheduler-serviceæ–‡ä»¶å’Œå¯åŠ¨kube-scheduler">åˆ›å»ºkube-scheduler serviceæ–‡ä»¶å’Œå¯åŠ¨kube-scheduler</h4>
<p>åˆ›å»ºkube-schedulerçš„serviceé…ç½®æ–‡ä»¶/usr/lib/systemd/system/kube-scheduler.serviceï¼š</p>
<pre><code>[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/scheduler
ExecStart=/usr/local/bin/kube-scheduler \
            $KUBE_LOGTOSTDERR \
            $KUBE_LOG_LEVEL \
            $KUBE_MASTER \
            $KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre>
<p>å¯åŠ¨kube-scheduler</p>
<pre><code>systemctl daemon-reload
systemctl enable kube-scheduler
systemctl start kube-scheduler
systemctl status kube-scheduler
</code></pre>
<h4 id="åˆ›å»ºkube-controller-manager-serviceæ–‡ä»¶å’Œå¯åŠ¨kube-controller-manager">åˆ›å»ºkube-controller-manager serviceæ–‡ä»¶å’Œå¯åŠ¨kube-controller-manager</h4>
<p>åˆ›å»ºkube-controller-managerçš„serviceé…ç½®æ–‡ä»¶/usr/lib/systemd/kube-controller-manager.serviceï¼š</p>
<pre><code>[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
EnvironmentFile=-/etc/kubernetes/config
EnvironmentFile=-/etc/kubernetes/controller-manager
ExecStart=/usr/local/bin/kube-controller-manager \
        $KUBE_LOGTOSTDERR \
        $KUBE_LOG_LEVEL \
        $KUBE_MASTER \
        $KUBE_CONTROLLER_MANAGER_ARGS
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
</code></pre>
<p>å¯åŠ¨kube-controller-manager</p>
<pre><code>systemctl daemon-reload
systemctl enable kube-controller-manager
systemctl start kube-controller-manager
systemctl status kube-controller-manager
</code></pre>
<h4 id="éªŒè¯masterèŠ‚ç‚¹åŠŸèƒ½">éªŒè¯masterèŠ‚ç‚¹åŠŸèƒ½</h4>
<pre><code># kubectl get componentstatuses
NAME                 STATUS    MESSAGE              ERROR
scheduler            Healthy   ok
controller-manager   Healthy   ok
etcd-1               Healthy   {&quot;health&quot;: &quot;true&quot;}
etcd-0               Healthy   {&quot;health&quot;: &quot;true&quot;}
etcd-2               Healthy   {&quot;health&quot;: &quot;true&quot;}
</code></pre>
<h2 id="kubernetesåŸºæœ¬æ¦‚å¿µ">ğŸŒ´KubernetesåŸºæœ¬æ¦‚å¿µ</h2>
<p>Kubernetesé›†ç¾¤æ¶æ„ï¼š<br>
<img src="https://liuhuipy.github.io/post-images/1591687453392.png" alt="" loading="lazy"></p>
<h3 id="master">Master</h3>
<p>Kubernetesé‡‡ç”¨Masterä½œä¸ºé›†ç¾¤æ§åˆ¶ä¸­å¿ƒèŠ‚ç‚¹ï¼Œæ¯ä¸ªKubernetesé›†ç¾¤é‡Œéœ€è¦æœ‰ä¸€ä¸ªMasterèŠ‚ç‚¹æ¥è´Ÿè´£æ•´ä¸ªé›†ç¾¤çš„ç®¡ç†å’Œæ§åˆ¶ï¼ŒMasterèŠ‚ç‚¹ä¸Šè¿è¡Œç€ä¸€ç»„è¿›ç¨‹ï¼š</p>
<ul>
<li>Kubernetes API Serverï¼ˆkube-apiserverï¼‰ï¼šæä¾›äº†HTTP Restæ¥å£çš„å…³é”®æœåŠ¡è¿›ç¨‹ï¼Œæ˜¯Kubernetesæ‰€æœ‰èµ„æºçš„å¢ã€åˆ ã€æ”¹ã€æŸ¥ç­‰æ“ä½œçš„å”¯ä¸€å…¥å£ï¼Œå¹¶æä¾›è®¤è¯ã€æˆæƒã€è®¿é—®æ§åˆ¶ã€APIæ³¨å†Œå’Œå‘ç°ç­‰æœºåˆ¶ï¼Œæ˜¯é›†ç¾¤æ§åˆ¶çš„å…¥å£è¿›ç¨‹ã€‚</li>
<li>Kubernetes Controller Managerï¼ˆkube-controller-managerï¼‰ï¼šKubernetesæ‰€æœ‰èµ„æºå¯¹è±¡çš„è‡ªåŠ¨åŒ–æ§åˆ¶ä¸­å¿ƒï¼Œè´Ÿè´£ç»´æŠ¤é›†ç¾¤çš„çŠ¶æ€ï¼Œæ¯”å¦‚æ•…éšœæ£€æµ‹ã€è‡ªåŠ¨æ‰©å±•ã€æ»šåŠ¨æ›´æ–°ç­‰ã€‚</li>
<li>Kubernetes Schedulerï¼ˆkube-schedulerï¼‰ï¼šè´Ÿè´£èµ„æºè°ƒåº¦ï¼ˆPodè°ƒåº¦ï¼‰çš„è¿›ç¨‹ã€‚</li>
</ul>
<h3 id="node">Node</h3>
<p>Kubernetesé›†ç¾¤ä¸­é™¤äº†MasterèŠ‚ç‚¹çš„å…¶ä»–èŠ‚ç‚¹ç§°ä¸ºNodeèŠ‚ç‚¹ã€‚ä¸Masterä¸€æ ·ï¼ŒNodeèŠ‚ç‚¹å¯ä»¥æ˜¯ä¸€å°ç‰©ç†ä¸»æœºï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€å°è™šæ‹Ÿæœºã€‚NodeèŠ‚ç‚¹æ‰æ˜¯Kubernetesé›†ç¾¤ä¸­çš„å·¥ä½œè´Ÿè½½èŠ‚ç‚¹ï¼Œæ¯ä¸ªNodeéƒ½ä¼šè¢«åˆ†é…ä¸€äº›å·¥ä½œè´Ÿè½½(Pod)ï¼Œå½“æŸä¸ªNodeå®•æœºæ—¶ï¼Œè¿™äº›è´Ÿè½½ä¼šè¢«åˆ†é…åˆ°å…¶ä»–å·¥ä½œèŠ‚ç‚¹ä¸­ã€‚æ¯ä¸ªNodeèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œç€ä»¥ä¸‹ä¸€ç»„å…³é”®è¿›ç¨‹ï¼š</p>
<ul>
<li>kubeletï¼šè´Ÿè´£Podå¯¹åº”çš„å®¹å™¨çš„åˆ›å»ºã€å¯åœç­‰ä»»åŠ¡ã€‚</li>
<li>kube-proxyï¼šå®ç°Kubernetes Serviceçš„é€šä¿¡ä¸è´Ÿè½½å‡è¡¡æœºåˆ¶çš„é‡è¦ç»„ä»¶ã€‚</li>
<li>Docker Engineï¼ˆDockerï¼‰ï¼šDockerå®¹å™¨å¼•æ“ï¼Œè´Ÿè´£å·¥ä½œèŠ‚ç‚¹çš„å®¹å™¨åˆ›å»ºå’Œç®¡ç†å·¥ä½œã€‚</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kuberneteså­¦ä¹ ç¬”è®°]]></title>
        <id>https://liuhuipy.github.io/post/kubernetes-node/</id>
        <link href="https://liuhuipy.github.io/post/kubernetes-node/">
        </link>
        <updated>2020-06-02T18:02:30.000Z</updated>
        <summary type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Kubernetes</strong> ï¼<br>
âœï¸ Kubernetesæƒå¨æŒ‡å—ç¬”è®°</p>
]]></summary>
        <content type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Kubernetes</strong> ï¼<br>
âœï¸ Kubernetesæƒå¨æŒ‡å—ç¬”è®°</p>
<!-- more -->
<h1 id="kuberneteså…¥é—¨">Kuberneteså…¥é—¨</h1>
<h2 id="kubernetesæ˜¯ä»€ä¹ˆ">Kubernetesæ˜¯ä»€ä¹ˆ</h2>
<p>Kubernetesæ˜¯ä¸€ä¸ªå®Œå¤‡çš„åˆ†å¸ƒå¼ç³»ç»Ÿæ”¯æ’‘å¹³å°ã€‚Kuberneteså…·æœ‰å®Œå¤‡çš„é›†ç¾¤ç®¡ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¤šå±‚æ¬¡çš„å®‰å…¨é˜²æŠ¤å’Œå‡†å…¥æœºåˆ¶ã€å¤šç§Ÿæˆ·åº”ç”¨æ”¯æ’‘èƒ½åŠ›ã€é€æ˜çš„æœåŠ¡æ³¨å†Œå’ŒæœåŠ¡å‘ç°æœºåˆ¶ã€å†…å»ºæ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨ã€å¼ºå¤§çš„æ•…éšœå‘ç°å’Œè‡ªæˆ‘ä¿®å¤èƒ½åŠ›ã€æœåŠ¡æ»šåŠ¨å‡çº§å’Œåœ¨çº¿æ‰©å®¹èƒ½åŠ›ã€å¯æ‰©å±•çš„èµ„æºè‡ªåŠ¨è°ƒåº¦æœºåˆ¶ï¼Œä»¥åŠå¤šç²’åº¦çš„èµ„æºé…é¢ç®¡ç†èƒ½åŠ›ã€‚</p>
<p>åœ¨Kubernetesä¸­ï¼ŒServiceï¼ˆæœåŠ¡ï¼‰æ˜¯åˆ†å¸ƒå¼é›†ç¾¤æ¶æ„çš„æ ¸å¿ƒï¼Œä¸€ä¸ªServiceå¯¹è±¡æ‹¥æœ‰å¦‚ä¸‹å…³é”®ç‰¹å¾ï¼š</p>
<ul>
<li>æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€æŒ‡å®šçš„åå­—ï¼ˆæ¯”å¦‚mysql-serverï¼‰ï¼›</li>
<li>æ‹¥æœ‰ä¸€ä¸ªè™šæ‹ŸIPï¼ˆCluster IPã€Service IPæˆ–VIPï¼‰å’Œç«¯å£å·ï¼›</li>
<li>èƒ½å¤Ÿæä¾›æŸç§è¿œç¨‹æœåŠ¡èƒ½åŠ›ï¼›</li>
<li>è¢«æ˜ å°„åˆ°äº†æä¾›è¿™ç§æœåŠ¡èƒ½åŠ›çš„ä¸€ç»„å®¹å™¨åº”ç”¨ä¸Šã€‚</li>
</ul>
<p>Serviceçš„æœåŠ¡è¿›ç¨‹éƒ½åŸºäºSocketé€šä¿¡æ–¹å¼å¯¹å¤–æä¾›æœåŠ¡ï¼Œæ¯”å¦‚Redisã€Memcacheã€MySQLã€WebServerï¼Œæˆ–è€…æ˜¯å®ç°äº†æŸä¸ªå…·ä½“ä¸šåŠ¡çš„ä¸€ä¸ªç‰¹å®šçš„TCP Serverè¿›ç¨‹ã€‚è™½ç„¶ä¸€ä¸ªServiceé€šå¸¸ç”±å¤šä¸ªç›¸å…³çš„è¿›ç¨‹æ¥æä¾›æœåŠ¡ï¼Œæ¯ä¸ªæœåŠ¡è¿›ç¨‹éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„ï¼ˆIP+Portï¼‰è®¿é—®ç‚¹ï¼Œä½†Kubernetesèƒ½å¤Ÿè®©æˆ‘ä»¬é€šè¿‡Serviceï¼ˆè™šæ‹ŸCluster IP+Service Portï¼‰è¿æ¥åˆ°æŒ‡å®šçš„Serviceä¸Šã€‚æœ‰äº†Kuberneteså†…å»ºçš„é€æ˜è´Ÿè½½å‡è¡¡å’Œæ•…éšœæ¢å¤æœºåˆ¶ï¼Œä¸ç®¡åç«¯æœ‰å¤šå°‘æœåŠ¡è¿›ç¨‹ï¼Œä¹Ÿä¸ç®¡æŸä¸ªæœåŠ¡è¿›ç¨‹æ˜¯å¦ä¼šç”±äºå‘ç”Ÿæ•…éšœè€Œé‡æ–°éƒ¨ç½²åˆ°å…¶ä»–æœºå™¨ï¼Œéƒ½ä¸ä¼šå½±å“åˆ°æˆ‘ä»¬å¯¹æœåŠ¡çš„æ­£å¸¸è°ƒç”¨ã€‚æ›´é‡è¦çš„æ˜¯è¿™ä¸ªServiceæœ¬èº«ä¸€æ—¦åˆ›å»ºå°±ä¸å†å˜åŒ–ã€‚</p>
<p>å®¹å™¨æä¾›äº†å¼ºå¤§çš„éš”ç¦»åŠŸèƒ½ï¼Œæ‰€ä»¥æœ‰å¿…è¦æŠŠä¸ºServiceæä¾›æœåŠ¡çš„è¿™ç»„è¿›ç¨‹æ”¾å…¥å®¹å™¨ä¸­è¿›è¡Œéš”ç¦»ã€‚ä¸ºæ­¤ï¼ŒKubernetesè®¾è®¡äº†Podå¯¹è±¡ï¼Œå°†æ¯ä¸ªæœåŠ¡è¿›ç¨‹åŒ…è£…åˆ°ç›¸åº”çš„Podä¸­ï¼Œä½¿å…¶æˆä¸ºPodä¸­è¿è¡Œçš„ä¸€ä¸ªå®¹å™¨ï¼ˆContainerï¼‰ã€‚ä¸ºäº†å»ºç«‹Serviceå’ŒPodé—´çš„å…³è”å…³ç³»ï¼ŒKubernetesé¦–å…ˆç»™æ¯ä¸ªPodè´´ä¸Šä¸€ä¸ªæ ‡ç­¾ï¼ˆLabelï¼‰ï¼Œç»™è¿è¡ŒMySQLçš„Podè´´ä¸Šname=mysqlæ ‡ç­¾ï¼Œç»™è¿è¡ŒPHPçš„Podè´´ä¸Šname=phpæ ‡ç­¾ï¼Œç„¶åç»™ç›¸åº”çš„Serviceå®šä¹‰æ ‡ç­¾é€‰æ‹©å™¨ï¼ˆLabel Selectorï¼‰ï¼Œæ¯”å¦‚MySQL Serviceçš„æ ‡ç­¾é€‰æ‹©å™¨çš„é€‰æ‹©æ¡ä»¶ä¸ºname=mysqlï¼Œæ„å‘³ç€è¯¥Serviceè¦ä½œç”¨äºæ‰€æœ‰åŒ…å«name=mysql Labelçš„Podä¸Šã€‚</p>
<p>Podè¿è¡Œåœ¨ä¸€ä¸ªæˆ‘ä»¬ç§°ä¸ºèŠ‚ç‚¹ï¼ˆNodeï¼‰çš„ç¯å¢ƒä¸­ï¼Œè¿™ä¸ªèŠ‚ç‚¹æ—¢å¯ä»¥æ˜¯ç‰©ç†æœºï¼Œä¹Ÿå¯ä»¥æ˜¯è™šæ‹Ÿæœºï¼Œé€šå¸¸ä¸€ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œå‡ ç™¾ä¸ªPodï¼›å…¶æ¬¡ï¼Œæ¯ä¸ªPodé‡Œè¿è¡Œç€ä¸€ä¸ªç‰¹æ®Šçš„è¢«ç§°ä¹‹ä¸ºPauseçš„å®¹å™¨ï¼Œå…¶ä»–å®¹å™¨åˆ™ä¸ºä¸šåŠ¡å®¹å™¨ï¼Œè¿™äº›ä¸šåŠ¡å®¹å™¨å…±äº«Pauseå®¹å™¨çš„ç½‘ç»œæ ˆå’ŒVolumeæŒ‚è½½å·ï¼Œå› æ­¤å®ƒä»¬ä¹‹é—´é€šä¿¡å’Œæ•°æ®äº¤æ¢æ›´ä¸ºé«˜æ•ˆã€‚</p>
<p>åœ¨é›†ç¾¤ç®¡ç†æ–¹é¢ï¼ŒKuberneteså°†é›†ç¾¤ä¸­çš„æœºå™¨åˆ’åˆ†ä¸ºä¸€ä¸ªMasterèŠ‚ç‚¹å’Œä¸€ç¾¤å·¥ä½œèŠ‚ç‚¹ï¼ˆNodeï¼‰ã€‚å…¶ä¸­ï¼Œåœ¨MasterèŠ‚ç‚¹ä¸Šè¿è¡Œç€é›†ç¾¤ç®¡ç†ç›¸å…³çš„ä¸€ç»„è¿›ç¨‹kube-apiserverã€kube-controller-managerå’Œkube-schedulerï¼Œè¿™äº›è¿›ç¨‹å®ç°äº†æ•´ä¸ªé›†ç¾¤çš„èµ„æºç®¡ç†ã€Podè°ƒåº¦ã€å¼¹æ€§ä¼¸ç¼©ã€å®‰å…¨æ§åˆ¶ã€ç³»ç»Ÿç›‘æ§å’Œçº é”™ç­‰ç®¡ç†åŠŸèƒ½ï¼Œå¹¶ä¸”éƒ½æ˜¯å…¨è‡ªåŠ¨å®Œæˆçš„ã€‚Nodeä½œä¸ºé›†ç¾¤ä¸­çš„å·¥ä½œèŠ‚ç‚¹ï¼Œè¿è¡ŒçœŸæ­£çš„åº”ç”¨ç¨‹åºï¼Œåœ¨Nodeä¸ŠKubernetesç®¡ç†çš„æœ€å°è¿è¡Œå•å…ƒæ˜¯Podã€‚Nodeä¸Šè¿è¡Œç€Kubernetesçš„kubeletã€kube-proxyæœåŠ¡è¿›ç¨‹ï¼Œè¿™äº›æœåŠ¡è¿›ç¨‹è´Ÿè´£Podçš„åˆ›å»ºã€å¯åŠ¨ã€ç›‘æ§ã€é‡å¯ã€é”€æ¯ï¼Œä»¥åŠå®ç°è½¯ä»¶æ¨¡å¼çš„è´Ÿè½½å‡è¡¡å™¨ã€‚</p>
<p>ä¼ ç»ŸITç³»ç»Ÿä¸­æœåŠ¡æ‰©å®¹å’ŒæœåŠ¡å‡çº§è¿™ä¸¤ä¸ªéš¾é¢˜ï¼Œåœ¨Kubernetesé›†ç¾¤ä¸­ï¼Œåªéœ€ä¸ºéœ€è¦æ‰©å®¹çš„Serviceå…³è”çš„Podåˆ›å»ºä¸€ä¸ªRCï¼ˆReplication Controllerï¼‰ï¼Œåˆ™è¯¥Serviceçš„æ‰©å®¹å·²è‡³äºåæ¥çš„Serviceå‡çº§ç­‰é—®é¢˜å°±è¿åˆƒè€Œè§£äº†ã€‚ä¸€ä¸ªRCå®šä¹‰æ–‡ä»¶ä¸­åŒ…å«3ä¸ªå…³é”®ä¿¡æ¯ã€‚</p>
<ul>
<li>ç›®æ ‡Podçš„å®šä¹‰</li>
<li>å‰¯æœ¬æ•°é‡ï¼ˆReplicasï¼‰</li>
<li>è¦ç›‘æ§çš„ç›®å½•Podçš„æ ‡ç­¾</li>
</ul>
<p>åœ¨åˆ›å»ºå¥½RCï¼ˆç³»ç»Ÿå°†è‡ªåŠ¨åˆ›å»ºå¥½Podï¼‰åï¼ŒKubernetesä¼šé€šè¿‡RCä¸­å®šä¹‰çš„Labelç­›é€‰å‡ºå¯¹åº”çš„Podå®ä¾‹å¹¶å®æ—¶ç›‘æ§å…¶çŠ¶æ€å’Œæ•°é‡ï¼Œå¦‚æœå®ä¾‹æ•°é‡å°‘äºå®šä¹‰çš„å‰¯æœ¬æ•°é‡ï¼ˆReplicasï¼‰ï¼Œåˆ™ä¼šæ ¹æ®RCä¸­å®šä¹‰çš„Podæ¨¡æ¿æ¥åˆ›å»ºä¸€ä¸ªæ–°çš„Podï¼Œç„¶åå°†æ­¤Podè°ƒåº¦åˆ°åˆé€‚çš„Nodeä¸Šå¯åŠ¨è¿è¡Œï¼Œç›´åˆ°Podå®ä¾‹çš„æ•°é‡è¾¾åˆ°é¢„å®šç›®æ ‡</p>
<h2 id="ä¸ºä»€ä¹ˆè¦ç”¨kubernetes">ä¸ºä»€ä¹ˆè¦ç”¨Kubernetes</h2>
<p>ä½¿ç”¨Kuberneteså°±æ˜¯åœ¨å…¨é¢æ‹¥æŠ±å¾®æœåŠ¡æ¶æ„ã€‚å¾®æœåŠ¡æ¶æ„çš„æ ¸å¿ƒæ˜¯å°†ä¸€ä¸ªå·¨å¤§çš„å•ä½“åº”ç”¨åˆ†è§£ä¸ºå¾ˆå¤šå°çš„äº’ç›¸è¿æ¥çš„å¾®æœåŠ¡ï¼Œä¸€ä¸ªå¾®æœåŠ¡èƒŒåå¯èƒ½æœ‰å¤šä¸ªå®ä¾‹å‰¯æœ¬åœ¨æ”¯æ’‘ï¼Œå‰¯æœ¬çš„æ•°é‡å¯èƒ½éšç€ç³»ç»Ÿçš„è´Ÿè·å˜åŒ–è€Œè¿›è¡Œè°ƒæ•´ï¼Œå†…åµŒçš„è´Ÿè½½å‡è¡¡å™¨åœ¨è¿™é‡Œå‘æŒ¥äº†é‡è¦ä½œç”¨ã€‚</p>
<p>Kubernetesç³»ç»Ÿæ¶æ„å…·å¤‡äº†è¶…å¼ºçš„æ¨ªå‘æ‰©å®¹èƒ½åŠ›ã€‚</p>
<h2 id="ä½¿ç”¨minikubeå¯åŠ¨ä¸€ä¸ªkubernetesé›†ç¾¤">ä½¿ç”¨Minikubeå¯åŠ¨ä¸€ä¸ªKubernetesé›†ç¾¤</h2>
<p>å®‰è£…å¹¶å¯åŠ¨ï¼š</p>
<pre><code># curl -Lo minikube http://kubernetes.oss-cn-hangzhou.aliyuncs.com/minikube/releases/v1.2.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; mv minikube /usr/local/bin/
# minikube start --vm-driver=none --registry-mirror=https://registry.docker-cn.com
</code></pre>
<h2 id="å®‰è£…kuberneteså•æœºç‰ˆ">å®‰è£…Kubernetesï¼ˆå•æœºç‰ˆï¼‰</h2>
<p>ï¼ˆ1ï¼‰å…³é—­CentOSè‡ªå¸¦çš„é˜²ç«å¢™æœåŠ¡ï¼š</p>
<pre><code># systemctl disable firewalld
# systemctl stop firewalld
</code></pre>
<p>ï¼ˆ2ï¼‰å®‰è£…etcdå’ŒKubernetesè½¯ä»¶ï¼š</p>
<pre><code>yum install -y etcd kubernetes
</code></pre>
<p>ï¼ˆ3ï¼‰æŒ‰ç…§é¡ºåºå¯åŠ¨æ‰€æœ‰çš„æœåŠ¡ï¼š</p>
<pre><code># systemctl start etcd
# systemctl start docker
# systemctl start kube-apiserver
# systemctl start kube-controller-manager
# systemctl start kube-scheduler
# systemctl start kubelet
# systemctl start kube-proxy
</code></pre>
<h3 id="å¯åŠ¨mysqlæœåŠ¡">å¯åŠ¨MySQLæœåŠ¡</h3>
<p>é¦–å…ˆä¸ºMySQLæœåŠ¡åˆ›å»ºä¸€ä¸ªRCå®šä¹‰æ–‡ä»¶ï¼šmysql-rc.yamlã€‚</p>
<pre><code>apiVersion: v1
kind: ReplicationController                         # å‰¯æœ¬æ§åˆ¶å™¨RC
metadata:
  name: mysql
spec:
  replicas: 1                                       # Podå‰¯æœ¬æœŸå¾…æ•°é‡
  selector:
    app: mysql                                      # ç¬¦åˆç›®æ ‡çš„Podæ‹¥æœ‰æ­¤æ ‡ç­¾
  template:                                         # æ ¹æ®æ­¤æ¨¡æ¿åˆ›å»ºPodçš„å‰¯æœ¬ï¼ˆå®ä¾‹ï¼‰
    metadata:
      labels:
        app: mysql                                  # Podå‰¯æœ¬æ‹¥æœ‰çš„æ ‡ç­¾ï¼Œå¯¹åº”RCçš„Selector
    spec:          
      containers:                                   # Podå†…å®¹å™¨çš„å®šä¹‰éƒ¨åˆ†
      - name: mysql                                 # å®¹å™¨çš„åç§°
        image: mysql                                # å®¹å™¨å¯¹åº”çš„Docker Image
        ports: 
        - containerPort: 3306                       # å®¹å™¨åº”ç”¨ç›‘å¬çš„ç«¯å£å·
        env:
        - name: MYSQL_ROOT_PASSWORD                 
          value: &quot;123456&quot;
</code></pre>
<p>yamlå®šä¹‰æ–‡ä»¶ä¸­çš„kindå±æ€§ï¼Œç”¨æ¥è¡¨æ˜æ­¤èµ„æºå¯¹è±¡çš„ç±»å‹ï¼Œæ¯”å¦‚è¿™é‡Œçš„å€¼ä¸ºâ€œReplicationControllerâ€ï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªRCï¼›specæ˜¯RCçš„ç›¸å…³å±æ€§å®šä¹‰ï¼Œå…¶ä¸­spec.replicasä»£è¡¨è¿è¡ŒPodå®ä¾‹çš„ä¸ªæ•°ï¼Œspec.selectoræ˜¯RCçš„Podæ ‡ç­¾ï¼ˆLabelï¼‰é€‰æ‹©å™¨ï¼Œå³ç›‘æ§å’Œç®¡ç†æ‹¥æœ‰è¿™äº›æ ‡ç­¾çš„Podå®ä¾‹ï¼Œç¡®ä¿å½“å‰é›†ç¾¤ä¸Šå§‹ç»ˆæœ‰ä¸”ä»…æœ‰replicasä¸ªPodå®ä¾‹åœ¨è¿è¡Œã€‚å½“é›†ç¾¤ä¸­è¿è¡Œçš„Podæ•°é‡å°äºreplicasæ—¶ï¼ŒRCä¼šæ ¹æ®spec.templateä¸€èŠ‚ä¸­å®šä¹‰çš„Podæ¨¡æ¿ç”Ÿæˆæ–°çš„Podå®ä¾‹ï¼Œspec.template.metadata.labelsæŒ‡å®šäº†è¯¥Podçš„æ ‡ç­¾ï¼Œéœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯ï¼šè¿™é‡Œçš„labelså¿…é¡»åŒ¹é…ä¹‹å‰çš„spec.selectorï¼Œå¦åˆ™æ­¤RCæ¯æ¬¡åˆ›å»ºäº†ä¸€ä¸ªæ— æ³•åŒ¹é…Labelçš„Podï¼Œå°±ä¼šä¸åœåœ°å°è¯•åˆ›å»ºæ–°çš„Podã€‚</p>
<p>åˆ›å»ºå¥½mysql-rc.yamlæ–‡ä»¶ä»¥åï¼Œä¸ºäº†å°†å®ƒå‘å¸ƒåˆ°Kubernetesé›†ç¾¤ä¸­ï¼Œæˆ‘ä»¬åœ¨MasterèŠ‚ç‚¹æ‰§è¡Œå‘½ä»¤ï¼š</p>
<pre><code># kubectl create -f mysql-rc.yaml
replicationcontroller &quot;mysql&quot; created
# kubectl get rc            æŸ¥çœ‹åˆšæ‰åˆ›å»ºçš„RC
NAME        DESIRED     CURRENT     AGE
mysql       1           1           1m
# kubectl get pods          æŸ¥çœ‹Podçš„åˆ›å»ºæƒ…å†µ
</code></pre>
<p>åˆ›å»ºä¸€ä¸ªä¸ä¹‹å…³è”çš„Kubernetes Serviceï¼Œ MySQLçš„å®šä¹‰æ–‡ä»¶ï¼ˆmysql-svc.yamlï¼‰ï¼š</p>
<pre><code>apiVersion: v1
kind: Service                               # è¡¨æ˜æ˜¯Kubernetes Service
metadata:
  name: mysql                               # Serviceçš„å…¨å±€å”¯ä¸€åç§°
spec:
  ports:
    - port: 3306                            # Serviceæä¾›æœåŠ¡çš„ç«¯å£å·
  selector:                                 # Serviceå¯¹åº”çš„Podæ‹¥æœ‰è¿™é‡Œå®šä¹‰çš„æ ‡ç­¾
    app: mysql
</code></pre>
<p>å…¶ä¸­ï¼Œmetadata.nameæ˜¯Serviceçš„æœåŠ¡åï¼ˆServiceNameï¼‰ï¼›portå±æ€§åˆ™å®šä¹‰äº†Serviceçš„è™šç«¯å£ï¼›spec.selectorç¡®å®šäº†å“ªäº›Podå‰¯æœ¬ï¼ˆå®ä¾‹ï¼‰å¯¹åº”åˆ°æœ¬æœåŠ¡ã€‚æˆ‘ä»¬é€šè¿‡kubectl createå‘½ä»¤åˆ›å»ºServiceå¯¹è±¡ã€‚</p>
<pre><code># kubectl create -f mysql-svc.yaml
service &quot;mysql&quot; created
# kubectl get svc                           æŸ¥çœ‹åˆšåˆšåˆ›å»ºçš„service
NAME        CLUSTER-IP      EXTERNAL-IP     PORT(S)     AGE
mysql       168.169.253.144 &lt;none&gt;          3306/TCP    45s
</code></pre>
<p>168.169.253.144æ˜¯Cluster IPåœ°å€ï¼Œè¿™æ˜¯ä¸€ä¸ªè™šåœ°å€ï¼ŒKubernetesé›†ç¾¤ä¸­å…¶ä»–æ–°åˆ›å»ºçš„Podå°±å¯ä»¥é€šè¿‡Serviceçš„Cluster IP+ç«¯å£å·3306æ¥è¿æ¥å’Œè®¿é—®ã€‚</p>
<p>åœ¨é€šå¸¸æƒ…å†µä¸‹ï¼ŒCluster IPæ˜¯åœ¨Serviceåˆ›å»ºåç”±Kubernetesç³»ç»Ÿè‡ªåŠ¨åˆ†é…çš„ï¼Œå…¶ä»–Podæ— æ³•é¢„å…ˆçŸ¥é“æŸä¸ªServiceçš„Cluster IPåœ°å€ï¼Œå› æ­¤éœ€è¦ä¸€ä¸ªæœåŠ¡å‘ç°æœºåˆ¶æ¥æ‰¾åˆ°è¿™ä¸ªæœåŠ¡ã€‚ä¸ºæ­¤ï¼ŒKuberneteså·§å¦™åœ°ä½¿ç”¨äº†Linuxç¯å¢ƒå˜é‡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬åªéœ€çŸ¥é“ï¼Œæ ¹æ®Serviceçš„å”¯ä¸€åå­—ï¼Œå®¹å™¨å¯ä»¥ä»ç¯å¢ƒå˜é‡ä¸­è·å–åˆ°Serviceå¯¹åº”çš„Cluster IPåœ°å€å’Œç«¯å£ï¼Œä»è€Œå‘èµ·äº†TCP/IPè¿æ¥è¯·æ±‚ã€‚</p>
<h3 id="å¯åŠ¨tomcatåº”ç”¨">å¯åŠ¨Tomcatåº”ç”¨</h3>
<p>åˆ›å»ºå¯¹åº”çš„RCæ–‡ä»¶myweb-rc.yamlï¼š</p>
<pre><code>apiVersion: v1
kind: ReplicationController
metadata:
  name: myweb
spec:
  replicas: 2
  selector:
    app: myweb
  template:
    metadata:
      labels:
        app: myweb
    spec:
      containers:
        - name: myweb
          image: kubeguide/tomcat-app:v1
          ports:
          - containerPort: 8080

</code></pre>
<p>åˆ›å»ºå¯¹åº”çš„Service</p>
<pre><code>apiVersion: v1
kind: Service
metadata:
  name: myweb
spec:
  type: NodePort
  ports:
    - port: 8080
      nodePort: 30001
  selector:
    app: myweb
</code></pre>
<p>type=NodePortå’ŒnodePort=30001çš„ä¸¤ä¸ªå±æ€§ï¼Œè¡¨æ˜æ­¤Serviceå¼€å¯äº†NodePortæ–¹å¼çš„å¤–ç½‘è®¿é—®æ¨¡å¼ï¼Œåœ¨Kubernetesé›†ç¾¤ä¹‹å¤–ï¼Œæ¯”å¦‚åœ¨æœ¬æœºçš„æµè§ˆå™¨é‡Œï¼Œå¯ä»¥é€šè¿‡30001è¿™ä¸ªç«¯å£è®¿é—®myweb</p>
<h2 id="kubernetesåŸºæœ¬æ¦‚å¿µå’Œæœ¯è¯­">KubernetesåŸºæœ¬æ¦‚å¿µå’Œæœ¯è¯­</h2>
<h3 id="master">Master</h3>
<p>Kubernetesé‡Œçš„MasteræŒ‡çš„æ˜¯é›†ç¾¤æ§åˆ¶èŠ‚ç‚¹ï¼Œæ¯ä¸ªKubernetesé›†ç¾¤é‡Œéœ€è¦æœ‰ä¸€ä¸ªMasterèŠ‚ç‚¹æ¥è´Ÿè´£æ•´ä¸ªé›†ç¾¤çš„ç®¡ç†å’Œæ§åˆ¶ï¼ŒåŸºæœ¬ä¸ŠKubernetesçš„æ‰€æœ‰æ§åˆ¶å‘½ä»¤éƒ½å‘ç»™å®ƒï¼Œå®ƒæ¥è´Ÿè´£å…·ä½“çš„æ‰§è¡Œè¿‡ç¨‹ã€‚MasterèŠ‚ç‚¹é€šå¸¸ä¼šå æ®ä¸€ä¸ªç‹¬ç«‹çš„æœåŠ¡å™¨ï¼ˆé«˜å¯ç”¨éƒ¨ç½²å»ºè®®ç”¨3å°æœåŠ¡å™¨ï¼‰ã€‚</p>
<p>MasterèŠ‚ç‚¹ä¸Šè¿è¡Œç€ä»¥ä¸‹ä¸€ç»„å…³é”®è¿›ç¨‹ï¼š</p>
<ul>
<li>Kubernetes API Serverï¼ˆkube-apiserverï¼‰ï¼šæä¾›äº†HTTP Restæ¥å£çš„å…³é”®æœåŠ¡è¿›ç¨‹ï¼Œæ˜¯Kubernetesé‡Œæ‰€æœ‰èµ„æºçš„å¢ã€åˆ ã€æ”¹ã€æŸ¥ç­‰æ“ä½œçš„å”¯ä¸€å…¥å£ï¼Œä¹Ÿæ˜¯é›†ç¾¤æ§åˆ¶çš„å…¥å£è¿›ç¨‹ï¼›</li>
<li>Kubernetes Controller Managerï¼ˆkube-controller-managerï¼‰ï¼šKubernetesé‡Œæ‰€æœ‰èµ„æºå¯¹è±¡çš„è‡ªåŠ¨åŒ–æ§åˆ¶ä¸­å¿ƒï¼›</li>
<li>Kubernetes Schedulerï¼ˆkube-schedulerï¼‰ï¼šè´Ÿè´£èµ„æºè°ƒåº¦ï¼ˆPodè°ƒåº¦ï¼‰çš„è¿›ç¨‹ã€‚</li>
</ul>
<p>åœ¨MasterèŠ‚ç‚¹ä¸Šè¿˜éœ€è¦å¯åŠ¨ä¸€ä¸ªetcdæœåŠ¡ï¼Œå› ä¸ºKubernetesé‡Œçš„æ‰€æœ‰èµ„æºå¯¹è±¡çš„æ•°æ®å…¨éƒ¨æ˜¯ä¿å­˜åœ¨etcdä¸­ã€‚</p>
<h3 id="node">Node</h3>
<p>é™¤äº†Masterï¼ŒKubernetesé›†ç¾¤ä¸­çš„å…¶ä»–æœºå™¨è¢«ç§°ä¸ºNodeèŠ‚ç‚¹ã€‚NodeèŠ‚ç‚¹æ‰æ˜¯Kubernetesé›†ç¾¤ä¸­çš„å·¥ä½œè´Ÿè½½èŠ‚ç‚¹ï¼Œæ¯ä¸ªNodeéƒ½ä¼šè¢«Masteråˆ†é…ä¸€äº›å·¥ä½œè´Ÿè½½ï¼ˆDockerå®¹å™¨ï¼‰ï¼Œå½“æŸä¸ªNodeå®•æœºæ—¶ï¼Œå…¶ä¸Šçš„å·¥ä½œè´Ÿè½½ä¼šè¢«Masterè‡ªåŠ¨è½¬ç§»åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šå»ã€‚<br>
æ¯ä¸ªNodeèŠ‚ç‚¹ä¸Šéƒ½è¿è¡Œç€ä»¥ä¸‹ä¸€ç»„å…³é”®è¿›ç¨‹ï¼š</p>
<ul>
<li>kubeletï¼šè´Ÿè´£Podå¯¹åº”çš„å®¹å™¨çš„åˆ›å»ºã€å¯åœç­‰ä»»åŠ¡ï¼ŒåŒæ—¶ä¸MasterèŠ‚ç‚¹å¯†åˆ‡åä½œï¼Œå®ç°é›†ç¾¤ç®¡ç†çš„åŸºæœ¬åŠŸèƒ½ï¼›</li>
<li>kube-proxyï¼šå®ç°Kubernetes Serviceçš„é€šä¿¡ä¸è´Ÿè½½å‡è¡¡æœºåˆ¶çš„é‡è¦ç»„ä»¶ï¼›</li>
<li>Docker Engineï¼ˆdockerï¼‰ï¼šDockerå¼•æ“ï¼Œè´Ÿè´£æœ¬æœºçš„å®¹å™¨åˆ›å»ºå’Œç®¡ç†å·¥ä½œã€‚</li>
</ul>
<p>NodeèŠ‚ç‚¹å¯ä»¥åœ¨è¿è¡ŒæœŸé—´åŠ¨æ€å¢åŠ åˆ°Kubernetesé›†ç¾¤ä¸­ï¼Œå‰ææ˜¯è¿™ä¸ªèŠ‚ç‚¹å·²ç»æ­£ç¡®å®‰è£…ã€é…ç½®å’Œå¯åŠ¨äº†ä¸Šè¿°å…³é”®è¿›ç¨‹ï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹kubeletä¼šå‘Masteræ³¨å†Œè‡ªå·±ï¼Œè¿™ä¹Ÿæ˜¯Kubernetesæ¨èçš„Nodeç®¡ç†æ–¹å¼ã€‚kubeletè¿›ç¨‹ä¼šå®šæ—¶å‘MasterèŠ‚ç‚¹æ±‡æŠ¥è‡ªèº«çš„æƒ…å†µï¼Œå¦‚æ“ä½œç³»ç»Ÿã€Dockerç‰ˆæœ¬ã€æœºå™¨çš„CPUå’Œå†…å­˜æƒ…å†µï¼Œä»¥åŠå½“å‰æœ‰å“ªäº›Podåœ¨è¿è¡Œç­‰ï¼Œè¿™æ ·Masterå¯ä»¥è·çŸ¥æ¯ä¸ªNodeçš„èµ„æºä½¿ç”¨æƒ…å†µï¼Œå¹¶å®ç°é«˜æ•ˆå‡è¡¡çš„èµ„æºè°ƒåº¦ç­–ç•¥ã€‚</p>
<p>æŸ¥çœ‹é›†ç¾¤ä¸­æœ‰å¤šå°‘ä¸ªNodeï¼š</p>
<pre><code># kubectl get nodes
NAME                STATUS      AGE
kubernetes-minion1  Ready       2d
</code></pre>
<p>é€šè¿‡kubectl describe node &lt;node_name&gt;æ¥æŸ¥çœ‹æŸä¸ªNodeçš„è¯¦ç»†ä¿¡æ¯ï¼š</p>
<pre><code># kubectl describe node kubernetes-minion1
</code></pre>
<ul>
<li>NodeåŸºæœ¬ä¿¡æ¯ï¼šåç§°ã€æ ‡ç­¾ã€åˆ›å»ºæ—¶é—´ï¼›</li>
<li>Nodeå½“å‰è¿è¡ŒçŠ¶æ€ï¼ŒNodeå¯åŠ¨ä»¥åä¼šåšä¸€ç³»åˆ—çš„è‡ªæ£€å·¥ä½œï¼Œæ¯”å¦‚ç£ç›˜æ˜¯å¦æ»¡äº†ï¼Œå¦‚æœæ»¡äº†å°±æ ‡æ³¨OutOfDisk=Trueï¼Œå¦åˆ™ç»§ç»­æ£€æŸ¥å†…å­˜æ˜¯å¦ä¸è¶³ï¼ˆå¦‚æœå†…å­˜ä¸è¶³ï¼Œå°±æ ‡æ³¨MemoryPressure=Trueï¼‰ï¼Œæœ€åä¸€åˆ‡æ­£å¸¸ï¼Œå°±è®¾ç½®ä¸ºReadyçŠ¶æ€ï¼ˆReady=Trueï¼‰ï¼Œè¯¥çŠ¶æ€è¡¨ç¤ºNodeå¤„äºå¥åº·çŠ¶æ€ï¼ŒMasterå°±å¯ä»¥åœ¨å…¶ä¸Šè°ƒåº¦æ–°çš„ä»»åŠ¡äº†ï¼›</li>
<li>Nodeçš„ä¸»æœºåœ°å€ä¸ä¸»æœºåï¼›</li>
<li>Nodeä¸Šçš„èµ„æºæ€»é‡ï¼šæè¿°Nodeå¯ç”¨çš„ç³»ç»Ÿèµ„æºï¼ŒåŒ…æ‹¬CPUã€å†…å­˜æ•°é‡ã€æœ€å¤§å¯è°ƒåº¦Podæ•°é‡ç­‰ï¼›</li>
<li>Nodeå¯åˆ†é…èµ„æºé‡ï¼šæè¿°Nodeå½“å‰å¯ç”¨äºåˆ†é…çš„èµ„æºé‡ï¼›</li>
<li>ä¸»æœºç³»ç»Ÿä¿¡æ¯ï¼šåŒ…æ‹¬ä¸»æœºçš„å”¯ä¸€æ ‡è¯†UUIDã€Linux kernelç‰ˆæœ¬å·ã€æ“ä½œç³»ç»Ÿç±»å‹ä¸ç‰ˆæœ¬ã€Kubernetesç‰ˆæœ¬å·ã€kubeletä¸kube-proxyçš„ç‰ˆæœ¬å·ç­‰ã€‚</li>
<li>å½“å‰æ­£åœ¨è¿è¡Œçš„Podåˆ—è¡¨æ¦‚è¦ä¿¡æ¯ï¼›</li>
<li>å·²åˆ†é…çš„èµ„æºä½¿ç”¨æ¦‚è¦ä¿¡æ¯ï¼›</li>
<li>Nodeç›¸å…³çš„Eventä¿¡æ¯ã€‚</li>
</ul>
<h3 id="pod">Pod</h3>
<p>Podæ˜¯Kubernetesçš„æœ€é‡è¦ä¹Ÿæœ€åŸºæœ¬çš„æ¦‚å¿µï¼Œæ¯ä¸ªPodéƒ½æœ‰ä¸€ä¸ªç‰¹æ®Šè¢«ç§°ä¸ºâ€œæ ¹å®¹å™¨â€çš„Pauseå®¹å™¨ã€‚Pauseå®¹å™¨å¯¹åº”çš„é•œåƒå±äºKuberneteså¹³å°çš„ä¸€éƒ¨åˆ†ï¼Œé™¤äº†Pauseå®¹å™¨ï¼Œæ¯ä¸ªPodè¿˜åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªç´§å¯†ç›¸å…³çš„ç”¨æˆ·ä¸šåŠ¡å®¹å™¨ã€‚</p>
<p>å¼•å…¥ä¸šåŠ¡æ— å…³ä¸”ä¸æ˜“æ­»äº¡çš„Pauseå®¹å™¨ä½œä¸ºPodçš„æ ¹å®¹å™¨ï¼Œä»¥å®ƒçš„çŠ¶æ€ä»£è¡¨æ•´ä¸ªå®¹å™¨ç»„çš„çŠ¶æ€ï¼ŒPodé‡Œçš„å¤šä¸ªä¸šåŠ¡å®¹å™¨å…±äº«Pauseå®¹å™¨çš„IPï¼Œå…±äº«Pauseå®¹å™¨æŒ‚è½½çš„Volumeã€‚</p>
<p>Kubernetesä¸ºæ¯ä¸ªPodéƒ½åˆ†é…äº†å”¯ä¸€çš„IPåœ°å€ï¼Œç§°ä¹‹ä¸ºPod IPï¼Œä¸€ä¸ªPodé‡Œçš„å¤šä¸ªå®¹å™¨å…±äº«Pod IPåœ°å€ã€‚Kubernetesè¦æ±‚åº•å±‚ç½‘ç»œæ”¯æŒé›†ç¾¤å†…ä»»æ„ä¸¤ä¸ªPodä¹‹é—´çš„TCP/IPç›´æ¥é€šä¿¡ï¼Œè¿™é€šå¸¸é‡‡ç”¨è™šæ‹ŸäºŒå±‚ç½‘ç»œæŠ€æœ¯æ¥å®ç°ï¼Œä¾‹å¦‚ï¼šFlannelã€Open vSwitchç­‰ï¼Œåœ¨Kubernetesé‡Œï¼Œä¸€ä¸ªPodé‡Œçš„å®¹å™¨ä¸å¦å¤–ä¸»æœºä¸Šçš„Podå®¹å™¨èƒ½å¤Ÿç›´æ¥é€šä¿¡ã€‚</p>
<p>Podæœ‰ä¸¤ç§ç±»å‹ï¼šæ™®é€šçš„Podä¸é™æ€Podï¼ˆStatic Podï¼‰ï¼Œåè€…ä¸å­˜æ”¾åœ¨Kubernetesçš„etcdå­˜å‚¨é‡Œï¼Œè€Œæ˜¯å­˜æ”¾åœ¨æŸä¸ªå…·ä½“çš„Nodeä¸Šçš„ä¸€ä¸ªå…·ä½“æ–‡ä»¶ä¸­ï¼Œå¹¶ä¸”åªåœ¨æ­¤Nodeä¸Šå¯åŠ¨è¿è¡Œã€‚è€Œæ™®é€šçš„Podä¸€æ—¦è¢«åˆ›å»ºï¼Œå°±ä¼šè¢«æ”¾å…¥åˆ°etcdä¸­å­˜å‚¨ï¼Œéšåä¼šè¢«Kubernetes Masterè°ƒåº¦åˆ°æŸä¸ªå…·ä½“çš„Nodeä¸Šå¹¶è¿›è¡Œç»‘å®šï¼Œéšåè¯¥Podè¢«å¯¹åº”çš„Nodeä¸Šçš„kubeletè¿›ç¨‹å®ä¾‹åŒ–æˆä¸€ç»„ç›¸å…³çš„Dockerå®¹å™¨å¹¶å¯åŠ¨èµ·æ¥ã€‚å½“Podé‡Œçš„æŸä¸ªå®¹å™¨åœæ­¢æ—¶ï¼ŒKubernetesä¼šè‡ªåŠ¨æ£€æµ‹åˆ°è¿™ä¸ªé—®é¢˜å¹¶ä¸”é‡æ–°å¯åŠ¨è¿™ä¸ªPodï¼ˆé‡å¯Podé‡Œçš„æ‰€æœ‰å®¹å™¨ï¼‰ï¼Œå¦‚æœPodæ‰€åœ¨çš„Nodeå®•æœºäº†ï¼Œåˆ™ä¼šå°†è¿™ä¸ªNodeä¸Šçš„æ‰€æœ‰Podé‡æ–°è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ä¸Šã€‚</p>
<p>Kubernetesé‡Œçš„æ‰€æœ‰èµ„æºå¯¹è±¡éƒ½å¯ä»¥é‡‡ç”¨yamlæˆ–è€…JSONæ ¼å¼çš„æ–‡ä»¶æ¥å®šä¹‰æˆ–æè¿°ï¼š</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: myweb
  labels:
    name: myweb
spec:
  containers:
  - name: myweb
    image: kubeguide/tomcat-app:v1
    ports:
    - containerPort: 8080
    env:
    - name: MYSQL_SERVICE_HOST
      value: 'mysql'
    - name: MYSQL_SERVICE_PORT
      value: '3306'
</code></pre>
<p>Kindä¸ºPodè¡¨æ˜è¿™æ˜¯ä¸€ä¸ªPodçš„å®šä¹‰ï¼Œmetadataé‡Œçš„nameå±æ€§ä¸ºPodçš„åå­—ï¼Œmetadataé‡Œè¿˜èƒ½å®šä¹‰èµ„æºå¯¹è±¡çš„æ ‡ç­¾ï¼ˆLabelï¼‰ï¼Œè¿™é‡Œå£°æ˜çš„mywebæ‹¥æœ‰ä¸€ä¸ªname=mywebçš„æ ‡ç­¾ï¼ˆLabelï¼‰ã€‚Podé‡Œæ‰€åŒ…å«çš„å®¹å™¨ç»„çš„å®šä¹‰åˆ™åœ¨specä¸€èŠ‚ä¸­å£°æ˜ï¼Œè¿™é‡Œå®šä¹‰äº†ä¸€ä¸ªåå­—ä¸ºmywebã€å¯¹åº”é•œåƒä¸ºkubeguide/tomcat-app:v1çš„å®¹å™¨ï¼Œè¯¥å®¹å™¨æ³¨å…¥åä¸ºMYSQL_SERVICE_HOST='mysql'å’ŒMYSQL_SERVICE_PORT='3306'çš„ç¯å¢ƒå˜é‡ï¼Œå¹¶ä¸”åœ¨8080ç«¯å£ä¸Šå¯åŠ¨å®¹å™¨è¿›ç¨‹ã€‚Podçš„IPåŠ ä¸Šè¿™é‡Œçš„å®¹å™¨ç«¯å£ï¼ˆcontainerPortï¼‰å°±ç»„æˆä¸€ä¸ªæ–°çš„æ¦‚å¿µ--Endpointï¼Œå®ƒä»£è¡¨ç€æ­¤Podé‡Œçš„ä¸€ä¸ªæœåŠ¡è¿›ç¨‹çš„å¯¹å¤–é€šä¿¡åœ°å€ã€‚ä¸€ä¸ªPodä¹Ÿå­˜åœ¨ç€å…·æœ‰å¤šä¸ªEndpointçš„æƒ…å†µï¼Œæ¯”å¦‚å½“æŠŠTomcatå®šä¹‰ä¸ºä¸€ä¸ªPodæ—¶ï¼Œå¯ä»¥å¯¹å¤–æš´éœ²ç®¡ç†ç«¯å£ä¸æœåŠ¡ç«¯å£è¿™ä¸¤ä¸ªEndpoint</p>
<p>æ¯ä¸ªPodéƒ½å¯ä»¥å¯¹å…¶èƒ½ä½¿ç”¨çš„æœåŠ¡å™¨ä¸Šçš„è®¡ç®—èµ„æºè®¾ç½®é™é¢ï¼Œå½“å‰å¯ä»¥è®¾ç½®é™é¢çš„è®¡ç®—èµ„æºæœ‰CPUå’ŒMemoryä¸¤ç§ï¼Œå…¶ä¸­CPUçš„èµ„æºå•ä½ä¸ºCPUï¼ˆCoreï¼‰çš„æ•°é‡ï¼Œæ˜¯ä¸€ä¸ªç»å¯¹å€¼è€Œéç›¸å¯¹å€¼ã€‚ä¸€ä¸ªCPUçš„é…é¢å¯¹äºç»å¤§å¤šæ•°å®¹å™¨æ¥è¯´æ˜¯ç›¸å½“å¤§çš„èµ„æºé…é¢ï¼Œåœ¨Kubernetesé‡Œï¼Œé€šå¸¸ä»¥åƒåˆ†ä¹‹ä¸€çš„CPUé…é¢ä¸ºæœ€å°å•ä½ï¼Œç”¨mæ¥è¡¨ç¤ºã€‚é€šå¸¸ä¸€ä¸ªå®¹å™¨çš„CPUé…é¢è¢«å®šä¹‰ä¸º100<sub>300mï¼Œå³å ç”¨0.1</sub>0.3ä¸ªCPUã€‚ç”±äºCPUé…é¢æ˜¯ä¸€ä¸ªç»å¯¹å€¼ï¼Œæ‰€ä»¥æ— è®ºåœ¨æ‹¥æœ‰ä¸€ä¸ªCoreçš„æœºå™¨ä¸Šï¼Œè¿˜æ˜¯åœ¨æ‹¥æœ‰48ä¸ªCoreçš„æœºå™¨ä¸Šï¼Œ100mè¿™ä¸ªé…é¢æ‰€ä»£è¡¨çš„çš„CPUçš„ä½¿ç”¨é‡éƒ½æ˜¯ä¸€æ ·çš„ã€‚ä¸CPUé…é¢ç±»ä¼¼ï¼ŒMemoryé…é¢ä¹Ÿæ˜¯ä¸€ä¸ªç»å¯¹å€¼ï¼Œå®ƒçš„å•ä½æ˜¯å†…å­˜å­—èŠ‚æ•°ã€‚</p>
<p>åœ¨Kubernetesé‡Œï¼Œä¸€ä¸ªè®¡ç®—èµ„æºè¿›è¡Œé…é¢é™å®šéœ€è¦è®¾å®šä»¥ä¸‹ä¸¤ä¸ªå‚æ•°ã€‚</p>
<ul>
<li>Requestsï¼šè¯¥èµ„æºçš„æœ€å°ç”³è¯·é‡ï¼Œç³»ç»Ÿå¿…é¡»æ»¡è¶³è¦æ±‚ã€‚</li>
<li>Limitsï¼šè¯¥èµ„æºæœ€å¤§å…è®¸ä½¿ç”¨çš„é‡ï¼Œä¸èƒ½è¢«çªç ´ï¼Œå½“å®¹å™¨è¯•å›¾ä½¿ç”¨è¶…è¿‡è¿™ä¸ªé‡çš„èµ„æºæ—¶ï¼Œå¯èƒ½ä¼šè¢«Kubernetes Killå¹¶é‡å¯ã€‚</li>
</ul>
<p>é€šå¸¸æˆ‘ä»¬ä¼šæŠŠRequestsè®¾ç½®ä¸ºä¸€ä¸ªæ¯”è¾ƒå°çš„æ•°å€¼ï¼Œç¬¦åˆå®¹å™¨å¹³æ—¶çš„å·¥ä½œè´Ÿè½½æƒ…å†µä¸‹çš„èµ„æºéœ€æ±‚ï¼Œè€ŒæŠŠLimitè®¾ç½®ä¸ºå³°å€¼è´Ÿè½½æƒ…å†µä¸‹èµ„æºå ç”¨çš„æœ€å¤§é‡ã€‚</p>
<pre><code>spec:
  containers:
  - name: db
    image: mysql
    resources:
      requests:
        memory: &quot;64Mi&quot;
        cpu: &quot;250m&quot;
      limits:
        memory: &quot;128Mi&quot;
        cpu: &quot;500m&quot;
</code></pre>
<h3 id="labelæ ‡ç­¾">Labelï¼ˆæ ‡ç­¾ï¼‰</h3>
<p>Labelæ˜¯Kubernetesç³»ç»Ÿä¸­å¦å¤–ä¸€ä¸ªæ ¸å¿ƒæ¦‚å¿µã€‚ä¸€ä¸ªLabelæ˜¯ä¸€ä¸ªkey=valueçš„é”®å€¼å¯¹ï¼Œå…¶ä¸­keyä¸valueç”±ç”¨æˆ·è‡ªå·±æŒ‡å®šã€‚Labelå¯ä»¥é™„åŠ åˆ°å„ç§èµ„æºå¯¹è±¡ä¸Šï¼Œæ¯”å¦‚Nodeã€Podã€Serviceã€RCç­‰ï¼Œä¸€ä¸ªèµ„æºå¯¹è±¡å¯ä»¥å®šä¹‰ä»»æ„æ•°é‡çš„Labelï¼ŒåŒä¸€ä¸ªLabelä¹Ÿå¯ä»¥è¢«æ·»åŠ åˆ°ä»»æ„æ•°é‡çš„èµ„æºå¯¹è±¡ä¸Šã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç»™æŒ‡å®šçš„èµ„æºå¯¹è±¡æ†ç»‘ä¸€ä¸ªæˆ–å¤šä¸ªä¸åŒçš„Labelæ¥å®ç°å¤šç»´åº¦çš„èµ„æºåˆ†ç»„ç®¡ç†åŠŸèƒ½ï¼Œä»¥ä¾¿äºçµæ´»ã€æ–¹ä¾¿åœ°è¿›è¡Œèµ„æºåˆ†é…ã€è°ƒåº¦ã€é…ç½®ã€éƒ¨ç½²ç­‰ç®¡ç†å·¥ä½œã€‚å¸¸ç”¨çš„Labelå¦‚ä¸‹ï¼š</p>
<pre><code>ç‰ˆæœ¬æ ‡ç­¾ï¼š&quot;release&quot;: &quot;stable&quot;, &quot;release&quot;: &quot;canary&quot;...
ç¯å¢ƒæ ‡ç­¾ï¼š&quot;environment&quot;: &quot;dev&quot;, &quot;environment&quot;: &quot;qa&quot;, &quot;environment&quot;: &quot;production&quot;...
æ¶æ„æ ‡ç­¾ï¼š&quot;tier&quot;: &quot;frontend&quot;, &quot;tier&quot;: &quot;backend&quot;, &quot;tier&quot;: &quot;middleware&quot;...
åˆ†åŒºæ ‡ç­¾ï¼š&quot;partition&quot;: &quot;customerA&quot;, &quot;partition&quot;: &quot;customerB&quot;...
è´¨é‡ç®¡æ§æ ‡ç­¾ï¼š&quot;track&quot;: &quot;daily&quot;, &quot;track&quot;: &quot;weekly&quot;...
</code></pre>
<p>Labelç›¸å½“äºæˆ‘ä»¬ç†Ÿæ‚‰çš„â€œæ ‡ç­¾â€ï¼Œç»™æŸä¸ªèµ„æºå¯¹è±¡å®šä¹‰ä¸€ä¸ªLabelï¼Œå°±ç›¸å½“äºç»™å®ƒæ‰“äº†ä¸€ä¸ªæ ‡ç­¾ï¼Œéšåå¯ä»¥é€šè¿‡Label Selectorï¼ˆæ ‡ç­¾é€‰æ‹©å™¨ï¼‰æŸ¥è¯¢å’Œç­›é€‰æ‹¥æœ‰æŸäº›Labelçš„èµ„æºå¯¹è±¡ï¼ŒKubernetesé€šè¿‡è¿™ç§æ–¹å¼å®ç°äº†ç±»ä¼¼SQLçš„ç®€å•åˆé€šç”¨çš„å¯¹è±¡æŸ¥è¯¢æœºåˆ¶ã€‚</p>
<p>Label Selectorå¯ä»¥è¢«ç±»æ¯”ä¸ºSQLè¯­å¥ä¸­çš„whereæŸ¥è¯¢æ¡ä»¶ï¼Œä¾‹å¦‚ï¼šname=redis-slaveè¿™ä¸ªLabel Selectorä½œç”¨äºPodæ—¶ï¼Œå¯ä»¥è¢«ç±»æ¯”ä¸ºselect * from pod where podâ€™s name=â€˜redis-slaveâ€™è¿™æ ·çš„è¯­å¥ã€‚</p>
<p>Label Selectoråœ¨Kubernetesä¸­çš„é‡è¦ä½¿ç”¨åœºæ™¯ï¼š</p>
<ul>
<li>kube-controllerè¿›ç¨‹é€šè¿‡èµ„æºå¯¹è±¡RCä¸Šå®šä¹‰çš„Label Selectoræ¥ç­›é€‰è¦ç›‘æ§çš„Podå‰¯æœ¬çš„æ•°é‡ï¼Œä»è€Œå®ç°Podå‰¯æœ¬çš„æ•°é‡å§‹ç»ˆç¬¦åˆé¢„æœŸè®¾å®šçš„å…¨è‡ªåŠ¨æ§åˆ¶æµç¨‹ã€‚</li>
<li>kube-proxyè¿›ç¨‹é€šè¿‡Serviceçš„Label Selectoræ¥é€‰æ‹©å¯¹åº”çš„Podï¼Œè‡ªåŠ¨å»ºç«‹èµ·æ¯ä¸ªServiceåˆ°å¯¹åº”Podçš„è¯·æ±‚è½¬å‘è·¯ç”±è¡¨ï¼Œä»è€Œå®ç°Serviceçš„æ™ºèƒ½è´Ÿè½½å‡è¡¡æœºåˆ¶ã€‚</li>
<li>é€šè¿‡å¯¹æŸäº›Nodeå®šä¹‰ç‰¹å®šçš„Labelï¼Œå¹¶ä¸”åœ¨Podå®šä¹‰æ–‡ä»¶ä¸­ä½¿ç”¨NodeSelectorè¿™ç§æ ‡ç­¾è°ƒåº¦ç­–ç•¥ï¼Œkube-schedulerè¿›ç¨‹å¯ä»¥å®ç°Podâ€œå®šå‘è°ƒåº¦â€çš„ç‰¹æ€§ã€‚</li>
</ul>
<h3 id="replication-controller">Replication Controller</h3>
<p>RCæ˜¯Kubernetesç³»ç»Ÿä¸­çš„æ ¸å¿ƒæ¦‚å¿µä¹‹ä¸€ï¼Œç®€å•æ¥è¯´å°±æ˜¯å®šä¹‰äº†ä¸€ä¸ªæœŸæœ›çš„åœºæ™¯ï¼Œå³å£°æ˜æŸç§Podçš„å‰¯æœ¬æ•°é‡åœ¨ä»»æ„æ—¶åˆ»éƒ½ç¬¦åˆæŸä¸ªé¢„æœŸå€¼ï¼Œæ‰€ä»¥RCçš„å®šä¹‰åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ªéƒ¨åˆ†ã€‚</p>
<ul>
<li>PodæœŸå¾…çš„å‰¯æœ¬æ•°ï¼ˆreplicasï¼‰</li>
<li>ç”¨äºç­›é€‰ç›®æ ‡Podçš„Label Selector</li>
<li>å½“Podçš„å‰¯æœ¬æ•°é‡å°äºé¢„æœŸæ•°é‡æ—¶ï¼Œç”¨äºåˆ›å»ºæ–°Podçš„Podæ¨¡æ¿ï¼ˆtemplateï¼‰<br>
ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„RCå®šä¹‰çš„ä¾‹å­ï¼Œå³ç¡®ä¿æ‹¥æœ‰tier=frontendæ ‡ç­¾çš„è¿™ä¸ªPodï¼ˆè¿è¡ŒTomcatï¼‰å®¹å™¨åœ¨æ•´ä¸ªKubernetesé›†ç¾¤ä¸­å§‹ç»ˆåªæœ‰ä¸€ä¸ªå‰¯æœ¬ï¼š</li>
</ul>
<pre><code>apiVersion: v1
kind: ReplicationController
metadata:
  name: frontend
spec:
  replicas: 1
  selector:
    tier: frontend
  template:
    metadata:
      labels:
        app: app-demo
        tier: frontend
      spec:
        containers:
        - name: tomcat-demo
          image: tomcat
          imagePullPolicy: IfNotPresent
          env:
          - name: GET_HOSTS_FROM
            value: dns
          ports:
          - containerPort: 80
</code></pre>
<p>å½“æˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªRCå¹¶æäº¤åˆ°Kubernetesé›†ç¾¤ä¸­ä»¥åï¼ŒMasterèŠ‚ç‚¹ä¸Šçš„Controller Managerç»„ä»¶å°±å¾—åˆ°é€šçŸ¥ï¼Œå®šæœŸå·¡æ£€ç³»ç»Ÿä¸­å½“å‰å­˜æ´»çš„ç›®æ ‡Podï¼Œå¹¶ç¡®ä¿ç›®æ ‡Podå®ä¾‹çš„æ•°é‡åˆšå¥½ç­‰äºæ­¤RCçš„æœŸæœ›å€¼ï¼Œå¦‚æœæœ‰è¿‡å¤šçš„Podå‰¯æœ¬åœ¨è¿è¡Œï¼Œç³»ç»Ÿå°±ä¼šåœæ‰ä¸€äº›Podï¼Œå¦åˆ™ç³»ç»Ÿå°±ä¼šå†è‡ªåŠ¨åˆ›å»ºä¸€äº›Podã€‚å¯ä»¥è¯´ï¼Œé€šè¿‡RCï¼ŒKuberneteså®ç°äº†ç”¨æˆ·åº”ç”¨é›†ç¾¤çš„é«˜å¯ç”¨æ€§ï¼Œå¹¶ä¸”å¤§å¤§å‡å°‘äº†ç³»ç»Ÿç®¡ç†å‘˜åœ¨ä¼ ç»ŸITç¯å¢ƒä¸­çš„æ‰‹åŠ¨è¿ç»´æ“ä½œã€‚</p>
<p>åœ¨è¿è¡Œæ—¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¿®æ”¹RCçš„å‰¯æœ¬æ•°é‡ï¼Œæ¥å®ç°Podçš„åŠ¨æ€ç¼©æ”¾ï¼ˆScalingï¼‰åŠŸèƒ½ï¼š</p>
<pre><code># kubectl scale rc redis-slave --replicas=3
scaled
</code></pre>
<p>åˆ é™¤RCå¹¶ä¸ä¼šå½±å“é€šè¿‡è¯¥RCå·²åˆ›å»ºå¥½çš„Podï¼Œè¦æƒ³åˆ é™¤æ‰€æœ‰Podï¼Œå¯ä»¥è®¾ç½®replicasçš„å€¼ä¸º0ï¼Œç„¶åæ›´æ–°è¯¥RCã€‚</p>
<p>ç”±äºReplication Controllerä¸Kubernetesä»£ç ä¸­æ¨¡å—Replication ControlleråŒåï¼ŒKubernetes v1.2ä¸­å‡çº§ä¸ºReplica Setï¼Œä¸RCå”¯ä¸€åŒºåˆ«æ˜¯ï¼šReplica Setsæ”¯æŒåŸºäºé›†åˆçš„Label selectorï¼ˆSet-based selectorï¼‰ï¼Œè€ŒRCåªæ”¯æŒåŸºäºç­‰å¼çš„Label Selectorï¼ˆequality-based selectorï¼‰ï¼Œè¿™ä½¿å¾—Replica Setçš„åŠŸèƒ½æ›´å¼ºã€‚</p>
<pre><code>apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: frontend
spec:
  selector:
    matchLabels:
      tier: frontend
    matchExpressions:
      - {key: tier, operator: In, values: [frontend]}
    template:
    ......
</code></pre>
<p>RCï¼ˆReplica Setï¼‰çš„ä¸€äº›ç‰¹æ€§ä¸ä½œç”¨ï¼š</p>
<ul>
<li>åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€šè¿‡å®šä¹‰ä¸€ä¸ªRCå®ç°Podçš„åˆ›å»ºè¿‡ç¨‹åŠå‰¯æœ¬æ•°é‡çš„è‡ªåŠ¨æ§åˆ¶ã€‚</li>
<li>RCé‡ŒåŒ…æ‹¬å®Œæ•´çš„Podå®šä¹‰æ¨¡æ¿ã€‚</li>
<li>RCé€šè¿‡Label Selectoræœºåˆ¶å®ç°å¯¹Podå‰¯æœ¬çš„è‡ªåŠ¨æ§åˆ¶ã€‚</li>
<li>é€šè¿‡æ”¹å˜RCé‡Œçš„Podå‰¯æœ¬æ•°é‡ï¼Œå¯ä»¥å®ç°Podçš„æ‰©å®¹æˆ–ç¼©å®¹åŠŸèƒ½ã€‚</li>
<li>é€šè¿‡æ”¹å˜RCé‡ŒPodæ¨¡æ¿ä¸­çš„é•œåƒç‰ˆæœ¬ï¼Œå¯ä»¥å®ç°Podçš„æ»šåŠ¨å‡çº§åŠŸèƒ½ã€‚</li>
</ul>
<h3 id="deployment">Deployment</h3>
<p>Deploymentæ˜¯Kubernetes v1.2å¼•å…¥çš„æ–°æ¦‚å¿µï¼Œå¼•å…¥çš„ç›®çš„æ˜¯ä¸ºäº†æ›´å¥½åœ°è§£å†³Podçš„ç¼–æ’é—®é¢˜ã€‚Deploymentåœ¨å†…éƒ¨ä½¿ç”¨äº†Replica Setæ¥å®ç°ç›®çš„ï¼Œæ— è®ºä»Deploymentçš„ä½œç”¨ä¸ç›®çš„ã€å®ƒçš„YAMLå®šä¹‰ï¼Œè¿˜æ˜¯ä»å®ƒçš„å…·ä½“å‘½ä»¤è¡Œæ“ä½œæ¥çœ‹ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥æŠŠå®ƒçœ‹ä½œRCçš„ä¸€æ¬¡å‡çº§ï¼Œä¸¤è€…çš„ç›¸ä¼¼åº¦è¶…è¿‡90%ã€‚</p>
<ul>
<li>åˆ›å»ºä¸€ä¸ªDeploymentå¯¹è±¡æ¥ç”Ÿæˆå¯¹åº”çš„Replica Setå¹¶å®ŒæˆPodå‰¯æœ¬çš„åˆ›å»ºè¿‡ç¨‹ã€‚</li>
<li>æ£€æŸ¥Deploymentçš„çŠ¶æ€æ¥çœ‹éƒ¨ç½²åŠ¨ä½œæ˜¯å¦å®Œæˆï¼ˆPodå‰¯æœ¬çš„æ•°é‡æ˜¯å¦è¾¾åˆ°é¢„æœŸçš„å€¼ï¼‰ã€‚</li>
<li>æ›´æ–°Deploymentä»¥åˆ›å»ºæ–°çš„Podï¼ˆæ¯”å¦‚é•œåƒå‡çº§ï¼‰ã€‚</li>
<li>æš‚åœDeploymentä»¥ä¾¿äºä¸€æ¬¡æ€§ä¿®æ”¹å¤šä¸ªPodTemplateSpecçš„é…ç½®é¡¹ï¼Œä¹‹åå†æ¢å¤Deploymentï¼Œè¿›è¡Œæ–°çš„å‘å¸ƒã€‚</li>
<li>æ‰©å±•Deploymentä»¥åº”å¯¹é«˜è´Ÿè½½ã€‚</li>
<li>æŸ¥çœ‹Deploymentçš„çŠ¶æ€ï¼Œä»¥æ­¤ä½œä¸ºå‘å¸ƒæ˜¯å¦æˆåŠŸçš„æŒ‡æ ‡ã€‚</li>
<li>æ¸…ç†ä¸å†éœ€è¦çš„æ—§ç‰ˆæœ¬ReplicaSetsã€‚</li>
</ul>
<p>åˆ›å»ºä¸€ä¸ªåä¸ºtomcat-deployment.yamlçš„Deploymentçš„æè¿°æ–‡ä»¶ï¼š</p>
<pre><code>apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 1
  selector:
    matchLabels:
      tier: frontend
    matchExpressions:
      - {key: tier, operator: In, values: [frontend]}
  template:
    metadata:
      labels:
        app: app-demo
        tier: frontend
    spec:
      containers:
      - name: tomcat-dmeo
        image: tomcat
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
</code></pre>
<p>è¿è¡Œå‘½ä»¤åˆ›å»ºDeploymentï¼š</p>
<pre><code># kubectl create -f tomcat-deployment.yaml
deployment &quot;tomcat-deploy&quot; created
# kubectl get deployments               æŸ¥çœ‹Deploymentçš„ä¿¡æ¯
NAME            DESIRED     CURRENT     UP-TO-DATE      AVAILABLE       AGE
tomcat-deploy   1           1           1               1               4m
</code></pre>
<ul>
<li>DESIREDï¼šPodå‰¯æœ¬æ•°é‡çš„æœŸæœ›å€¼ï¼Œå³Deploymenté‡Œå®šä¹‰çš„Replicaã€‚</li>
<li>CURRENTï¼šå½“å‰Replicaçš„å€¼ï¼Œå®é™…ä¸Šæ˜¯Deploymentæ‰€åˆ›å»ºçš„Replica Seté‡Œçš„Replicaå€¼ï¼Œè¿™ä¸ªå€¼ä¸æ–­å¢åŠ ï¼Œç›´åˆ°è¾¾åˆ°DESIREDä¸ºæ­¢ï¼Œè¡¨æ˜æ•´ä¸ªéƒ¨ç½²è¿‡ç¨‹å®Œæˆã€‚</li>
<li>UP-TO-DATEï¼šæœ€æ–°ç‰ˆæœ¬çš„Podçš„å‰¯æœ¬æ•°é‡ï¼Œç”¨äºæŒ‡ç¤ºåœ¨æ»šåŠ¨å‡çº§çš„è¿‡ç¨‹ä¸­ï¼Œæœ‰å¤šå°‘ä¸ªPodå‰¯æœ¬å·²ç»æˆåŠŸå‡çº§ã€‚</li>
<li>AVAILABELï¼šå½“å‰é›†ç¾¤ä¸­å¯ç”¨çš„Podå‰¯æœ¬æ•°é‡ï¼Œå³é›†ç¾¤ä¸­å½“å‰å­˜æ´»çš„Podæ•°é‡ã€‚</li>
</ul>
<h3 id="horizontal-pod-autoscalingpodæ¨ªå‘è‡ªåŠ¨æ‰©å®¹hpa">Horizontal Pod Autoscalingï¼ˆPodæ¨ªå‘è‡ªåŠ¨æ‰©å®¹ï¼ŒHPAï¼‰</h3>
<p>HPAä¸ä¹‹å‰çš„RCã€Deploymentä¸€æ ·ï¼Œä¹Ÿå±äºä¸€ç§Kubernetesèµ„æºå¯¹è±¡ã€‚é€šè¿‡è¿½è¸ªåˆ†æRCæ§åˆ¶çš„æ‰€æœ‰ç›®æ ‡Podçš„è´Ÿè½½å˜åŒ–æƒ…å†µï¼Œæ¥ç¡®å®šæ˜¯å¦éœ€è¦é’ˆå¯¹æ€§åœ°è°ƒæ•´ç›®æ ‡Podçš„å‰¯æœ¬æ•°ï¼Œè¿™æ˜¯HPAçš„å®ç°åŸç†ã€‚HPAå¯ä»¥æœ‰ä»¥ä¸‹ä¸¤ç§æ–¹å¼ä½œä¸ºPodè´Ÿè½½çš„åº¦é‡æŒ‡æ ‡ã€‚</p>
<ul>
<li>CPUUtilizationPercentageã€‚</li>
<li>åº”ç”¨ç¨‹åºè‡ªå®šä¹‰çš„åº¦é‡æŒ‡æ ‡ï¼Œæ¯”å¦‚æœåŠ¡åœ¨æ¯ç§’å†…çš„ç›¸åº”çš„è¯·æ±‚æ•°ï¼ˆTPSæˆ–QPSï¼‰</li>
</ul>
<p>CPUUtilizationPercentageæ˜¯ä¸€ä¸ªç®—æœ¯å¹³å‡å€¼ï¼Œå³ç›®æ ‡Podæ‰€æœ‰å‰¯æœ¬è‡ªèº«çš„CPUåˆ©ç”¨ç‡çš„å¹³å‡å€¼ã€‚ä¸€ä¸ªPodè‡ªèº«çš„CPUåˆ©ç”¨ç‡æ˜¯è¯¥Podå½“å‰CPUçš„ä½¿ç”¨é‡é™¤ä»¥å®ƒçš„Pod Requestçš„å€¼ï¼Œæ¯”å¦‚æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªPodçš„Pod Requestä¸º0.4ï¼Œè€Œå½“å‰Podçš„CPUä½¿ç”¨é‡ä¸º0.2ï¼Œåˆ™å®ƒçš„CPUä½¿ç”¨ç‡ä¸º50%ï¼Œå¦‚æ­¤ä¸€æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç®—å‡ºæ¥ä¸€ä¸ªRCæ§åˆ¶çš„æ‰€æœ‰Podå‰¯æœ¬çš„CPUåˆ©ç”¨ç‡çš„ç®—æœ¯å¹³å‡å€¼ã€‚å¦‚æœæŸä¸€æ—¶åˆ»CPUUtilizationPercentageçš„å€¼è¶…è¿‡80%ï¼Œåˆ™æ„å‘³ç€å½“å‰Podå‰¯æœ¬æ•°å¯èƒ½ä¸è¶³ä»¥æ”¯æ’‘æ¥ä¸‹æ¥æ›´å¤šçš„è¯·æ±‚ï¼Œéœ€è¦è¿›è¡ŒåŠ¨æ€æ‰©å®¹ï¼Œè€Œå½“è¯·æ±‚é«˜å³°æ—¶æ®µè¿‡å»åï¼ŒPodçš„CPUåˆ©ç”¨ç‡åˆä¼šé™ä¸‹æ¥ï¼Œæ­¤æ—¶å¯¹åº”çš„Podå‰¯æœ¬æ•°åº”è¯¥è‡ªåŠ¨å‡å°‘åˆ°ä¸€ä¸ªåˆç†çš„æ°´å¹³ã€‚</p>
<pre><code>apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: php-apache
  namespace: default
spec:
  maxReplicas: 10
  minReplicas: 1
  scaleTargetRef:
    kind: Deployment
    name: php-apache
  targetCPUUtilizationPercentage: 80
</code></pre>
<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡kubectl createå‘½ä»¤åˆ›å»ºä¸€ä¸ªHPAèµ„æºå¯¹è±¡ï¼Œè¿˜èƒ½é€šè¿‡ä¸‹é¢çš„ç®€å•å‘½ä»¤ç›´æ¥åˆ›å»ºç­‰ä»·çš„HPAå¯¹è±¡ï¼š</p>
<pre><code># kubectl autoscale deployment php-apache --cpu-percent=80 --min=1 --max=10
</code></pre>
<h3 id="service">Service</h3>
<p>Serviceä¹Ÿæ˜¯Kubernetesé‡Œçš„æœ€æ ¸å¿ƒçš„èµ„æºå¯¹è±¡ä¹‹ä¸€ï¼ŒKubernetesé‡Œçš„æ¯ä¸ªServiceå…¶å®å°±æ˜¯å¾®æœåŠ¡æ¶æ„ä¸­çš„ä¸€ä¸ªâ€œå¾®æœåŠ¡â€ï¼ŒKubernetesçš„Serviceå®šä¹‰ä¸€ä¸ªæœåŠ¡çš„è®¿é—®å…¥å£åœ°å€ï¼Œå‰ç«¯çš„åº”ç”¨ï¼ˆPodï¼‰é€šè¿‡è¿™ä¸ªå…¥å£åœ°å€è®¿é—®å…¶èƒŒåçš„ä¸€ç»„ç”±Podå‰¯æœ¬ç»„æˆçš„é›†ç¾¤å®ä¾‹ï¼ŒServiceä¸Podå‰¯æœ¬é›†ç¾¤ä¹‹é—´é€šè¿‡Label Selectoræ¥å®ç°æ— ç¼å¯¹æ¥çš„ã€‚RCçš„ä½œç”¨å®é™…ä¸Šæ˜¯ä¿è¯Serviceçš„æœåŠ¡èƒ½åŠ›å’ŒæœåŠ¡è´¨é‡å§‹ç»ˆå¤„äºé¢„æœŸçš„æ ‡å‡†ã€‚</p>
<p>é€šè¿‡åˆ†æã€è¯†åˆ«å¹¶å»ºæ¨¡ç³»ç»Ÿä¸­çš„æ‰€æœ‰æœåŠ¡ä¸ºå¾®æœåŠ¡--Kubernetes Serviceï¼Œæœ€ç»ˆæˆ‘ä»¬çš„ç³»ç»Ÿç”±å¤šä¸ªæä¾›ä¸åŒä¸šåŠ¡èƒ½åŠ›è€Œåˆå½¼æ­¤çš„å¾®æœåŠ¡å•å…ƒæ‰€ç»„æˆï¼ŒæœåŠ¡ä¹‹é—´é€šè¿‡TCP/IPè¿›è¡Œé€šä¿¡ï¼Œä»è€Œå½¢æˆäº†æˆ‘ä»¬å¼ºå¤§è€Œåˆçµæ´»çš„å¼¹æ€§ç½‘æ ¼ï¼Œæ‹¥æœ‰äº†å¼ºå¤§çš„åˆ†å¸ƒå¼èƒ½åŠ›ã€å¼¹æ€§æ‰©å±•èƒ½åŠ›ã€å®¹é”™èƒ½åŠ›ã€‚</p>
<p>æ—¢ç„¶æ¯ä¸ªPodéƒ½ä¼šè¢«åˆ†é…ä¸€ä¸ªå•ç‹¬çš„IPåœ°å€ï¼Œè€Œä¸”æ¯ä¸ªPodéƒ½æä¾›äº†ä¸€ä¸ªç‹¬ç«‹çš„Endpointï¼ˆPod IP+ContainerPortï¼‰ä»¥è¢«å®¢æˆ·ç«¯è®¿é—®ï¼Œç°åœ¨å¤šä¸ªPodå‰¯æœ¬ç»„æˆäº†ä¸€ä¸ªé›†ç¾¤æ¥æä¾›æœåŠ¡ï¼Œé‚£ä¹ˆå®¢æˆ·ç«¯å¦‚ä½•æ¥è®¿é—®å®ƒä»¬å‘¢ï¼Ÿä¸€èˆ¬çš„åšæ³•æ˜¯éƒ¨ç½²ä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨ï¼Œä¸ºè¿™ç»„Podå¼€å¯ä¸€ä¸ªå¯¹å¤–çš„æœåŠ¡ç«¯å£å¦‚8000ï¼Œå¹¶ä¸”å°†è¿™äº›Podçš„Endpointåˆ—è¡¨åŠ å…¥8000ç«¯å£çš„è½¬å‘åˆ—è¡¨ä¸­ï¼Œå®¢æˆ·ç«¯å°±å¯ä»¥é€šè¿‡è´Ÿè½½å‡è¡¡å™¨çš„å¯¹å¤–IPåœ°å€+æœåŠ¡ç«¯å£æ¥è®¿é—®æ­¤æœåŠ¡ï¼Œè€Œå®¢æˆ·ç«¯çš„è¯·æ±‚æœ€åè¢«è½¬å‘åˆ°å“ªä¸ªPodï¼Œç”±è´Ÿè½½å‡è¡¡å™¨çš„ç®—æ³•æ‰€å†³å®šã€‚</p>
<p>Kubernetesæä¾›çš„kube-proxyè¿›ç¨‹æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„è´Ÿè½½å‡è¡¡å™¨ï¼Œå®ƒè´Ÿè´£æŠŠå¯¹Serviceçš„è¯·æ±‚è½¬å‘åˆ°åç«¯çš„æŸä¸ªPodå®ä¾‹ä¸Šï¼Œå¹¶åœ¨å†…éƒ¨å®ç°æœåŠ¡çš„è´Ÿè½½å‡è¡¡ä¸ä¼šè¯ä¿æŒæœºåˆ¶ã€‚Serviceä¸æ˜¯å…¬ç”¨ä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨çš„IPåœ°å€ï¼Œè€Œæ˜¯æ¯ä¸ªServiceåˆ†é…äº†ä¸€ä¸ªå…¨å±€å”¯ä¸€çš„è™šæ‹ŸIPåœ°å€ï¼Œè¿™ä¸ªè™šæ‹ŸIPè¢«ç§°ä¸ºCluster IPã€‚è¿™æ ·æ¯ä¸ªæœåŠ¡å°±å˜æˆäº†å…·å¤‡å”¯ä¸€IPåœ°å€çš„é€šä¿¡èŠ‚ç‚¹ï¼ŒæœåŠ¡è°ƒç”¨å°±å˜æˆæœ€åŸºç¡€çš„TCPé€šä¿¡ã€‚</p>
<p>å®šä¹‰ä¸€ä¸ªåä¸ºtomcat-serviceçš„Serviceï¼ŒæœåŠ¡ç«¯å£ä¸º8080ï¼Œæ‹¥æœ‰tier=frontendè¿™ä¸ªLabelçš„æ‰€æœ‰Podå®ä¾‹éƒ½å±äºå®ƒï¼š</p>
<pre><code>apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
spec:
  ports:
  - port: 8080
  selector:
    tier: frontend
</code></pre>
<p>ä½¿ç”¨kubectl create -f tomcat-server.yamlè¿è¡Œè¿™ä¸ªServiceï¼Œæ³¨æ„åˆ°tomcat-deployment.yamlé‡Œå®šä¹‰çš„Tomcatçš„Podåˆšå¥½æ‹¥æœ‰è¿™ä¸ªæ ‡ç­¾ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆšæ‰åˆ›å»ºçš„tomcat-serviceå·²ç»å¯¹åº”åˆ°äº†ä¸€ä¸ªPodå®ä¾‹ï¼Œè¿è¡Œä¸‹é¢çš„å‘½ä»¤å¯ä»¥æŸ¥çœ‹tomcat-serviceçš„Endpointåˆ—è¡¨ï¼Œå…¶ä¸­172.17.1.3æ˜¯Podçš„IPåœ°å€ï¼Œç«¯å£8080æ˜¯Containeræš´éœ²çš„ç«¯å£ï¼š</p>
<pre><code># kubectl get endpoints
NAME                ENDPOINTS               AGE
kubernetes          192.168.18.131:6443     15d
tomcat-service      172.17.1.3              1m
# kubectl get svc tomcat-service -o yaml            è·å–tomcat-serviceåˆ†é…çš„Cluster IPåŠæ›´å¤šçš„ä¿¡æ¯
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: ...
  name: tomcat-service
  namespace: default
  resourceVersion: &quot;23964&quot;
  selfLink: /api/v1/namespaces/default/services/tomcat-service
  uid: ...
spec:
  clusterIP: 169.169.65.227         
  ...
  type: ClusterIP
status:
  loadBalancer: {}
</code></pre>
<p>Kubernetes Serviceæ”¯æŒå¤šä¸ªEndpointï¼Œåœ¨å­˜åœ¨å¤šä¸ªEndpointçš„æƒ…å†µä¸‹ï¼Œè¦æ±‚æ¯ä¸ªEndpointå®šä¹‰ä¸€ä¸ªåå­—æ¥åŒºåˆ†ï¼Œä¸‹é¢æ˜¯Tomcatå¤šç«¯å£çš„Serviceå®šä¹‰æ ·ä¾‹ï¼š</p>
<pre><code>apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
spec:
  ports:
  - port: 800
    name: service-port
  - port: 8005
    name: shutdown-port
</code></pre>
<p>ç»™å¤šä¸ªç«¯å£å‘½åæ–¹ä¾¿Kubernetesçš„æœåŠ¡å‘ç°æœºåˆ¶ã€‚é¦–å…ˆæ¯ä¸ªKubernetesä¸­çš„Serviceéƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„Cluster IPåŠå”¯ä¸€çš„åå­—ï¼Œè€Œåå­—æ˜¯ç”±å¼€å‘è€…è‡ªå·±å®šä¹‰çš„ï¼Œéƒ¨ç½²æ—¶ä¹Ÿæ²¡å¿…è¦æ”¹å˜ï¼Œæ‰€ä»¥å®Œå…¨å¯ä»¥å›ºå®šåœ¨é…ç½®ä¸­ã€‚æ¥ä¸‹æ¥çš„é—®é¢˜æ˜¯å¦‚ä½•é€šè¿‡Serviceçš„åå­—æ‰¾åˆ°å¯¹åº”çš„Cluster IPï¼Ÿæœ€æ—©Kubernetesé‡‡ç”¨äº†Linuxç¯å¢ƒå˜é‡çš„æ–¹å¼è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå³æ¯ä¸ªServiceç”Ÿæˆä¸€äº›å¯¹åº”çš„Linuxç¯å¢ƒå˜é‡ï¼ˆENVï¼‰ï¼Œå¹¶åœ¨æ¯ä¸ªPodçš„å®¹å™¨åœ¨å¯åŠ¨æ—¶ï¼Œè‡ªåŠ¨æ³¨å…¥è¿™äº›ç¯å¢ƒå˜é‡ã€‚è€ƒè™‘åˆ°ç¯å¢ƒå˜é‡çš„æ–¹å¼è·å–Serviceçš„IPä¸ç«¯å£çš„æ–¹å¼ä»ç„¶ä¸å¤ªæ–¹ä¾¿ï¼Œä¸å¤Ÿç›´è§‚ï¼Œåæ¥Kubernetesé€šè¿‡Add-Onå¢å€¼åŒ…çš„æ–¹å¼å¼•å…¥äº†DNSç³»ç»Ÿï¼ŒæŠŠæœåŠ¡åä½œä¸ºDNSåŸŸåï¼Œè¿™æ ·ä¸€æ¥ï¼Œç¨‹åºå°±å¯ä»¥ç›´æ¥ä½¿ç”¨æœåŠ¡åæ¥å»ºç«‹é€šä¿¡è¿æ¥äº†ã€‚ç›®å‰Kubernetesä¸Šçš„å¤§éƒ¨åˆ†åº”ç”¨éƒ½å·²ç»é‡‡ç”¨äº†DNSè¿™äº›æ–°å…´çš„æœåŠ¡å‘ç°æœºåˆ¶ã€‚</p>
<h4 id="å¤–éƒ¨ç³»ç»Ÿè®¿é—®serviceçš„é—®é¢˜">å¤–éƒ¨ç³»ç»Ÿè®¿é—®Serviceçš„é—®é¢˜</h4>
<p>Kubernetesæä¾›ä¸‰ç§IPï¼š</p>
<ul>
<li>Node IPï¼šNodeèŠ‚ç‚¹çš„IPåœ°å€</li>
<li>Pod IPï¼š Podçš„IPåœ°å€</li>
<li>Cluster IPï¼šServiceçš„IPåœ°å€</li>
</ul>
<p>Node IPæ˜¯Kubernetesé›†ç¾¤ä¸­æ¯ä¸ªèŠ‚ç‚¹çš„ç‰©ç†ç½‘å¡çš„IPåœ°å€ï¼Œè¿™æ˜¯ä¸€ä¸ªçœŸå®å­˜åœ¨çš„ç‰©ç†ç½‘ç»œï¼Œæ‰€æœ‰å±äºè¿™ä¸ªç½‘ç»œçš„æœåŠ¡å™¨ä¹‹é—´éƒ½èƒ½é€šè¿‡è¿™ä¸ªç½‘ç»œç›´æ¥é€šä¿¡ã€‚Pod IPæ˜¯æ¯ä¸ªPodçš„IPåœ°å€ï¼Œå®ƒæ˜¯Docker Engineæ ¹æ®docker0ç½‘æ¡¥çš„IPåœ°å€æ®µè¿›è¡Œåˆ†é…çš„ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„äºŒå±‚ç½‘ç»œï¼ŒKubernetesè¦æ±‚ä½äºä¸åŒNodeä¸Šçš„Podå¯ä»¥å½¼æ­¤ç›´æ¥é€šä¿¡ï¼Œæ‰€ä»¥Kubernetesé‡Œä¸€ä¸ªPodé‡Œçš„å®¹å™¨è®¿é—®å¦å¤–ä¸€ä¸ªPodé‡Œçš„å®¹å™¨ï¼Œå°±æ˜¯é€šè¿‡Pod IPæ‰€åœ¨çš„è™šæ‹ŸäºŒå±‚ç½‘ç»œè¿›è¡Œé€šä¿¡çš„ï¼Œè€ŒçœŸå®çš„TCP/IPæµé‡åˆ™æ˜¯é€šè¿‡Node IPæ‰€åœ¨çš„ç‰©ç†ç½‘å¡æµå‡ºçš„ã€‚</p>
<p>Clustor IPä¹Ÿæ˜¯ä¸€ä¸ªè™šæ‹ŸIPï¼Œä½†æ›´åƒæ˜¯ä¸€ä¸ªâ€œä¼ªé€ â€çš„IPç½‘ç»œï¼š</p>
<ul>
<li>Cluster IPä»…ä»…ä½œç”¨äºKubernetes Serviceè¿™ä¸ªå¯¹è±¡ï¼Œå¹¶ç”±Kubernetesç®¡ç†å’Œåˆ†é…IPåœ°å€</li>
<li>Cluster IPæ— æ³•è¢«Pingï¼Œå› ä¸ºæ²¡æœ‰ä¸€ä¸ªå®ä½“ç½‘ç»œå¯¹è±¡æ¥å“åº”</li>
<li>Cluster IPåªèƒ½ç»“åˆService Portç»„æˆä¸€ä¸ªå…·ä½“çš„é€šä¿¡ç«¯å£ï¼Œå•ç‹¬çš„Cluster IPä¸å…·å¤‡TCP/IPé€šä¿¡çš„åŸºç¡€ï¼Œå¹¶ä¸”å®ƒä»¬å±äºKubernetesé›†ç¾¤è¿™æ ·çš„ä¸€ä¸ªå°é—­çš„ç©ºé—´ï¼Œé›†ç¾¤ä¹‹å¤–çš„èŠ‚ç‚¹å¦‚æœè¦è®¿é—®è¿™ä¸ªé€šä¿¡ç«¯å£ï¼Œåˆ™éœ€è¦åšä¸€äº›é¢å¤–çš„å·¥ä½œ</li>
<li>åœ¨Kubernetesé›†ç¾¤ä¹‹å†…ï¼ŒNode IPç½‘ã€Pod IPç½‘ä¸Cluster IPç½‘ä¹‹é—´çš„é€šä¿¡ï¼Œé‡‡ç”¨çš„æ˜¯Kubernetesè‡ªå·±è®¾è®¡çš„ä¸€ç§ç¼–ç¨‹æ–¹å¼çš„ç‰¹æ®Šçš„è·¯ç”±è§„åˆ™ï¼Œä¸æˆ‘ä»¬ç†ŸçŸ¥çš„IPè·¯ç”±æœ‰å¾ˆå¤§ä¸åŒ</li>
</ul>
<p>Serviceçš„Cluster IPå±äºKubernetesé›†ç¾¤å†…éƒ¨çš„åœ°å€ï¼Œæ— æ³•åœ¨é›†ç¾¤å¤–éƒ¨ç›´æ¥ä½¿ç”¨è¿™ä¸ªåœ°å€ï¼Œé‚£ä¹ˆç”¨æˆ·å¦‚ä½•è®¿é—®å®ƒå‘¢ï¼Ÿé‡‡ç”¨NodePortï¼š</p>
<pre><code>apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
spec:
  type: NodePort
  ports:
  - port: 8080
    nodePort: 31002
  selector:
    tier: frontend
</code></pre>
<p>å…¶ä¸­ï¼ŒnodePort: 31002è¿™ä¸ªå±æ€§è¡¨æ˜æˆ‘ä»¬æ‰‹åŠ¨æŒ‡å®štomcat-serviceçš„NodePortä¸º31002ï¼Œå¦åˆ™Kubernetesä¼šè‡ªåŠ¨åˆ†é…ä¸€ä¸ªå¯ç”¨çš„ç«¯å£ã€‚NodePortçš„å®ç°æ–¹å¼æ˜¯åœ¨Kubernetesé›†ç¾¤é‡Œçš„æ¯ä¸ªNodeä¸Šä¸ºéœ€è¦å¤–éƒ¨è®¿é—®çš„Serviceå¼€å¯ä¸€ä¸ªå¯¹åº”çš„TCPç›‘å¬ç«¯å£ï¼Œå¤–éƒ¨ç³»ç»Ÿåªè¦ç”¨ä»»æ„ä¸€ä¸ªNodeçš„IPåœ°å€+å…·ä½“çš„NodePortç«¯å£å·å³å¯è®¿é—®æ­¤æœåŠ¡ã€‚ä½†æ˜¯NodePortè¿˜æ²¡æœ‰å®Œå…¨è§£å†³å¤–éƒ¨è®¿é—®Serviceçš„æ‰€æœ‰é—®é¢˜ï¼Œæ¯”å¦‚è´Ÿè½½å‡è¡¡é—®é¢˜ï¼Œå‡å¦‚æˆ‘ä»¬çš„é›†ç¾¤ä¸­æœ‰10ä¸ªNodeï¼Œæ­¤æ—¶æœ€å¥½æœ‰ä¸€ä¸ªè´Ÿè½½å‡è¡¡å™¨ï¼ˆå¦‚Load balancerç»„ä»¶ï¼‰ï¼Œå¤–éƒ¨çš„è¯·æ±‚åªéœ€è®¿é—®æ­¤è´Ÿè½½å‡è¡¡å™¨çš„IPåœ°å€ï¼Œç”±è´Ÿè½½å‡è¡¡å™¨è´Ÿè´£è½¬å‘æµé‡åˆ°åé¢æŸä¸ªNodeçš„NodePortä¸Šã€‚</p>
<p>Load balancerç»„ä»¶ç‹¬ç«‹äºKubernetesé›†ç¾¤ä¹‹å¤–ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªç¡¬ä»¶çš„è´Ÿè½½å‡è¡¡å™¨ï¼Œæˆ–è€…æ˜¯ä»¥è½¯ä»¶æ–¹å¼å®ç°çš„HAProxyæˆ–è€…Nginxã€‚å¯¹äºæ¯ä¸ªServiceï¼Œæˆ‘ä»¬é€šå¸¸éœ€è¦é…ç½®ä¸€ä¸ªå¯¹åº”çš„Load balancerå®ä¾‹æ¥è½¬å‘æµé‡åˆ°åç«¯çš„Nodeä¸Šï¼Œè¿™çš„ç¡®å¢åŠ äº†å·¥ä½œé‡åŠå‡ºé”™çš„æ¦‚ç‡ã€‚äºæ˜¯Kubernetesæä¾›äº†è‡ªåŠ¨åŒ–çš„è§£å†³æ–¹æ¡ˆï¼ŒæŠŠServiceçš„type=NodePortæ”¹ä¸ºtype=LoadBalancerï¼Œæ­¤æ—¶Kubernetesä¼šè‡ªåŠ¨é™ˆä½³é¢–å¯¹åº”çš„Load balancerå®ä¾‹å¹¶è¿”å›å®ƒçš„IPåœ°å€ä¾›å¤–éƒ¨å®¢æˆ·ç«¯ä½¿ç”¨ã€‚</p>
<h3 id="volumeå­˜å‚¨å·">Volumeï¼ˆå­˜å‚¨å·ï¼‰</h3>
<p>Volumeæ˜¯Podä¸­èƒ½å¤Ÿè¢«å¤šä¸ªå®¹å™¨è®¿é—®çš„å…±äº«ç›®å½•ã€‚Kubernetesä¸­çš„Volumeå®šä¹‰åœ¨Podä¸Šï¼Œç„¶åè¢«ä¸€ä¸ªPodé‡Œçš„å¤šä¸ªå®¹å™¨æŒ‚è½½åˆ°å…·ä½“çš„æ–‡ä»¶ç›®å½•ä¸‹ï¼›å…¶æ¬¡ï¼ŒKubernetesä¸­çš„Volumeä¸Podçš„ç”Ÿå‘½å‘¨æœŸç›¸åŒï¼Œä½†ä¸å®¹å™¨çš„ç”Ÿå‘½å‘¨æœŸä¸ç›¸å…³ï¼Œå½“å®¹å™¨ç»ˆæ­¢æˆ–é‡å¯æ—¶ï¼ŒVolumeä¸­çš„æ•°æ®ä¹Ÿä¸ä¼šä¸¢å¤±ã€‚Kubernetesæ”¯æŒå¤šç§ç±»å‹çš„Volumeï¼Œæ¯”å¦‚GlusterFSã€Cephç­‰å…ˆè¿›çš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚</p>
<p>æˆ‘ä»¬ç»™ä¹‹å‰çš„Tomcat Podå¢åŠ ä¸€ä¸ªåå­—ä¸ºdatavolçš„Volumeï¼Œå¹¶ä¸”Mountåˆ°å®¹å™¨çš„/mydata-dataç›®å½•ä¸Šï¼š</p>
<pre><code>template:
  metadata:
    labels:
      app: app-demo
      tier: frontend
  spec:
    volumes:
      - name: datavol
        emptyDir: {}
    containers:
    - name: tomcat-demo
      image: tomcat
      volumeMounts:
        - mountPath: /mydata-data
          name: datavol
      imagePullPolicy: IfNotPresent
</code></pre>
<h4 id="emptydir">emptyDir</h4>
<p>ä¸€ä¸ªemptyDir Volumeæ˜¯åœ¨Podåˆ†é…åˆ°Nodeæ—¶åˆ›å»ºçš„ã€‚å®ƒçš„åˆå§‹å†…å®¹ä¸ºç©ºï¼Œå¹¶ä¸”æ— éœ€æŒ‡å®šå®¿ä¸»æœºä¸Šå¯¹åº”çš„ç›®å½•æ–‡ä»¶ï¼Œå› ä¸ºè¿™æ˜¯Kubernetesè‡ªåŠ¨åˆ†é…çš„ä¸€ä¸ªç›®å½•ï¼Œå½“Podä»Nodeä¸Šç§»é™¤æ—¶ï¼ŒemptyDirä¸­çš„æ•°æ®ä¹Ÿä¼šè¢«æ°¸ä¹…åˆ é™¤ã€‚emptyDirçš„ä¸€äº›ç”¨é€”ï¼š</p>
<ul>
<li>ä¸´æ—¶ç©ºé—´</li>
<li>é•¿æ—¶é—´ä»»åŠ¡çš„ä¸­é—´è¿‡ç¨‹CheckPointçš„ä¸´æ—¶ä¿å­˜ç›®å½•</li>
<li>ä¸€ä¸ªå®¹å™¨éœ€è¦ä»å¦ä¸€ä¸ªå®¹å™¨ä¸­è·å–æ•°æ®çš„ç›®å½•ï¼ˆå¤šå®¹å™¨å…±äº«ç›®å½•ï¼‰</li>
</ul>
<h4 id="hostpath">hostPath</h4>
<p>hostPathä¸ºåœ¨Podä¸ŠæŒ‚è½½å®¿ä¸»æœºä¸Šçš„æ–‡ä»¶æˆ–ç›®å½•ï¼Œå®ƒé€šå¸¸å¯ä»¥ç”¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š</p>
<ul>
<li>å®¹å™¨åº”ç”¨ç¨‹åºç”Ÿæˆçš„æ—¥å¿—æ–‡ä»¶éœ€è¦æ°¸ä¹…ä¿å­˜æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å®¿ä¸»æœºçš„é«˜é€Ÿæ–‡ä»¶ç³»ç»Ÿè¿›è¡Œå­˜å‚¨</li>
<li>éœ€è¦è®¿é—®å®¿ä¸»æœºä¸ŠDockerå¼•æ“å†…éƒ¨æ•°æ®ç»“æ„çš„å®¹å™¨åº”ç”¨æ—¶ï¼Œå¯ä»¥é€šè¿‡å®šä¹‰hostPathä¸ºå®¿ä¸»æœº/var/lib/dockerç›®å½•ï¼Œä½¿å®¹å™¨å†…éƒ¨åº”ç”¨å¯ä»¥ç›´æ¥è®¿é—®Dockerçš„æ–‡ä»¶ç³»ç»Ÿã€‚</li>
</ul>
<h4 id="gcepersistentdisk">gcePersistentDisk</h4>
<p>ä½¿ç”¨è¿™ç§ç±»å‹çš„Volumeè¡¨ç¤ºä½¿ç”¨è°·æ­Œå…±æœ‰äº‘æä¾›çš„æ°¸ä¹…ç£ç›˜å­˜æ”¾Volumeçš„æ•°æ®</p>
<h4 id="awselasticblockstore">awsElasticBlockStore</h4>
<p>è¯¥ç±»å‹çš„Volumeä½¿ç”¨äºšé©¬é€Šå…¬æœ‰äº‘æä¾›çš„EBS Volumeå­˜å‚¨æ•°æ®ã€‚</p>
<p>å…¶ä»–ç±»å‹çš„Volumeï¼šNFSã€iscsiã€flockerã€rbdã€glusterfsç­‰</p>
<h3 id="namespaceå‘½åç©ºé—´">Namespaceï¼ˆå‘½åç©ºé—´ï¼‰</h3>
<p>Namespaceæ˜¯Kubernetesç³»ç»Ÿä¸­çš„å¦ä¸€ä¸ªéå¸¸é‡è¦çš„æ¦‚å¿µï¼ŒNamespaceåœ¨å¾ˆå¤šæƒ…å†µä¸‹ç”¨äºå®ç°å¤šç§Ÿæˆ·çš„èµ„æºéš”ç¦»ã€‚Namespaceé€šè¿‡å°†é›†ç¾¤å†…éƒ¨çš„èµ„æºå¯¹è±¡â€œåˆ†é…â€åˆ°ä¸åŒçš„Namespaceä¸­ï¼Œå½¢æˆé€»è¾‘ä¸Šåˆ†ç»„çš„ä¸åŒé¡¹ç›®ã€å°ç»„æˆ–ç”¨æˆ·ç»„ï¼Œä¾¿äºä¸åŒçš„åˆ†ç»„åœ¨å…±äº«ä½¿ç”¨æ•´ä¸ªé›†ç¾¤çš„èµ„æºçš„åŒæ—¶è¿˜èƒ½è¢«åˆ†åˆ«ç®¡ç†ã€‚</p>
<p>Kubernetesé›†ç¾¤åœ¨å¯åŠ¨åï¼Œä¼šåˆ›å»ºä¸€ä¸ªåä¸ºâ€œdefaultâ€çš„Namespaceï¼Œé€šè¿‡kubectlå¯ä»¥æŸ¥çœ‹åˆ°ï¼š</p>
<pre><code># kubectl get namespaces
NAME        LABELS      STATUS
default     &lt;none&gt;      Active
</code></pre>
<p>å¦‚æœç”¨æˆ·åˆ›å»ºçš„Podã€RCã€Serviceä¸ç‰¹åˆ«æŒ‡å®šNamespaceï¼Œéƒ½å°†è¢«ç³»ç»Ÿåˆ›å»ºåˆ°è¿™ä¸ªé»˜è®¤çš„åä¸ºdefaultçš„Namespaceä¸­ã€‚Namespaceçš„å®šä¹‰å¾ˆç®€å•ï¼š</p>
<pre><code>apiVersion: v1
kind: Namespace
metadata:
  name: development
</code></pre>
<p>ä¸€æ—¦åˆ›å»ºäº†Namespaceï¼Œæˆ‘ä»¬åœ¨åˆ›å»ºèµ„æºå¯¹è±¡æ—¶å°±å¯ä»¥æŒ‡å®šè¿™ä¸ªèµ„æºå¯¹è±¡å±äºå“ªä¸ªNamespaceã€‚æ¯”å¦‚åœ¨ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä¸ºbusyboxçš„Podï¼Œæ”¾å…¥developmentè¿™ä¸ªNamespaceé‡Œï¼š</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: development
spec:
  containers:
  - image: busybox
    command:
      - sleep
      - &quot;3600&quot;
    name: busybox
</code></pre>
<p>åœ¨kubectlå‘½ä»¤ä¸­åŠ å…¥--namespaceå‚æ•°æ¥æŸ¥çœ‹æŸä¸ªå‘½åç©ºé—´ä¸­çš„å¯¹è±¡ï¼š</p>
<pre><code># kubectl get pods --namespace=development
NAME        READY       STATUS      RESTARTS    AGE
busybox     1/1         Running     0           1m
</code></pre>
<p>å½“æˆ‘ä»¬ç»™æ¯ä¸ªç§Ÿæˆ·åˆ›å»ºä¸€ä¸ªNamespaceæ¥å®ç°å¤šç§Ÿæˆ·çš„èµ„æºéš”ç¦»æ—¶ï¼Œè¿˜èƒ½ç»“åˆKubernetesçš„èµ„æºé…é¢ç®¡ç†ï¼Œé™å®šä¸åŒç§Ÿæˆ·èƒ½å ç”¨çš„èµ„æºï¼Œä¾‹å¦‚CPUä½¿ç”¨é‡ã€å†…å­˜ä½¿ç”¨é‡ç­‰ã€‚</p>
<h1 id="kuberneteså®è·µæŒ‡å—">Kuberneteså®è·µæŒ‡å—</h1>
<h2 id="kuberneteså®‰è£…ä¸é…ç½®">Kuberneteså®‰è£…ä¸é…ç½®</h2>
<p>æœ¬æœºä½¿ç”¨Centos7.4ï¼Œéœ€è¦å…³é—­é˜²ç«å¢™æœåŠ¡ï¼š</p>
<pre><code># systemctl disable firewalld
# systemctl stop firewalld
# setenforce 0
</code></pre>
<h3 id="1å®‰è£…kubeadmå’Œç›¸å…³å·¥å…·">1.å®‰è£…Kubeadmå’Œç›¸å…³å·¥å…·</h3>
<p>æ·»åŠ æ–‡ä»¶/etc/yum.repos.d/kubernetes.repoï¼Œå†…å®¹å¦‚ä¸‹ï¼š</p>
<pre><code>[kubernetes]
name=Kubernetes Repo
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=0
enable=1
</code></pre>
<p>ç„¶åyum installå®‰è£…kubeadmå’Œç›¸å…³å·¥å…·ï¼Œå¯åŠ¨DockeræœåŠ¡ä¸kubeletæœåŠ¡ï¼Œå¹¶è®¾ç½®å¼€æœºå¯åŠ¨ï¼š</p>
<pre><code># yum install -y docker kubelet kubeadm kubectl kubernetes-cni
# systemctl enable docker &amp;&amp; systemctl start docker 
# systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<h3 id="2ä¸‹è½½kubernetesçš„ç›¸å…³é•œåƒ">2.ä¸‹è½½Kubernetesçš„ç›¸å…³é•œåƒ</h3>
<pre><code>[root@kubernetes-master ~]# docker pull warrior/pause-amd64:3.0
Trying to pull repository docker.io/warrior/pause-amd64 ... 
3.0: Pulling from docker.io/warrior/pause-amd64
a3ed95caeb02: Pull complete 
ce150f7a21ec: Pull complete 
Digest: sha256:35e1d4e39ad85c8ec163d0741882cc6442233385d914766a0db77e9e18776b90
Status: Downloaded newer image for docker.io/warrior/pause-amd64:3.0
[root@kubernetes-master ~]# docker tag warrior/pause-amd64:3.0 gcr.io/google_containers/pause-amd64:3.0
[root@kubernetes-master ~]# docker pull warrior/etcd-amd64:3.0.17
Trying to pull repository docker.io/warrior/etcd-amd64 ... 
3.0.17: Pulling from docker.io/warrior/etcd-amd64
9db6bc3045a3: Pull complete 
11f056d9da6e: Pull complete 
78d5c8d6ad80: Pull complete 
Digest: sha256:76cfdd5b54c3f4baec36c46a107a5fca321e2b9ebcb1ca8b09ff06c423558190
Status: Downloaded newer image for docker.io/warrior/etcd-amd64:3.0.17
[root@kubernetes-master ~]# 
[root@kubernetes-master ~]# docker tag warrior/etcd-amd64:3.0.17 gcr.io/google_containers/etcd-amd64:3.0.17
[root@kubernetes-master ~]# docker pull warrior/kube-apiserver-amd64:v1.6.0
Trying to pull repository docker.io/warrior/kube-apiserver-amd64 ... 
v1.6.0: Pulling from docker.io/warrior/kube-apiserver-amd64
bd4b2003aa95: Pull complete 
d6570e7cf860: Pull complete 
Digest: sha256:6b49095296d74f57e5c4971d5cbaa4f31099fe081aa32c14aaad6a1731fc43cb
Status: Downloaded newer image for docker.io/warrior/kube-apiserver-amd64:v1.6.0
[root@kubernetes-master ~]# docker tag warrior/kube-apiserver-amd64:v1.6.0 gci.io/google_containers/kube-apiserver-amd64:v1.6.0
[root@kubernetes-master ~]# docker pull warrior/kube-scheduler-amd64:v1.6.0
Trying to pull repository docker.io/warrior/kube-scheduler-amd64 ... 
v1.6.0: Pulling from docker.io/warrior/kube-scheduler-amd64
bd4b2003aa95: Already exists 
3d0373d7af87: Pull complete 
Digest: sha256:727fd20c622bc20485501fceb856b7b7161cd20a71778d3292459e2acca670f7
Status: Downloaded newer image for docker.io/warrior/kube-scheduler-amd64:v1.6.0
[root@kubernetes-master ~]# docker tag warrior/kube-scheduler-amd64:v1.6.0 gcr.io/google_containers/kube-scheduler-amd64:v1.6.0
[root@kubernetes-master ~]# docker pull warrior/kube-controller-manager-amd64:v1.6.0
Trying to pull repository docker.io/warrior/kube-controller-manager-amd64 ... 
v1.6.0: Pulling from docker.io/warrior/kube-controller-manager-amd64
bd4b2003aa95: Already exists 
d0ac0a1d98e3: Pull complete 
Digest: sha256:3528d32313a23e12b6e28cf10eec50b69f652ce2dd8abde621da45088e133aab
Status: Downloaded newer image for docker.io/warrior/kube-controller-manager-amd64:v1.6.0
[root@kubernetes-master ~]# docker tag warrior/kube-controller-manager-amd64:v1.6.0 gcr.io/google_containers/kube-controller-manager-amd64:v1.6.0
[root@kubernetes-master ~]# docker pull warrior/kube-proxy-amd64:v1.6.0
Trying to pull repository docker.io/warrior/kube-proxy-amd64 ... 
v1.6.0: Pulling from docker.io/warrior/kube-proxy-amd64
eed9f2fe5754: Pull complete 
6ac89e3b5f3b: Pull complete 
8d4ff2906840: Pull complete 
Digest: sha256:4b6e4c9b5800c7156cb2a6ca296891123ba8cede7667c494e3ed76ba8ef0f94b
Status: Downloaded newer image for docker.io/warrior/kube-proxy-amd64:v1.6.0
[root@kubernetes-master ~]# docker tag warrior/kube-proxy-amd64:v1.6.0 gcr.io/google_containers/kube-proxy-amd64:v1.6.0
[root@kubernetes-master ~]# docker pull gysan/dnsmasq-metrics-amd64:1.0
Trying to pull repository docker.io/gysan/dnsmasq-metrics-amd64 ... 
1.0: Pulling from docker.io/gysan/dnsmasq-metrics-amd64
c0cb142e4345: Pull complete 
a3ed95caeb02: Pull complete 
08935cb095f1: Pull complete 
Digest: sha256:69f62c72d8423677d508779ef37dc4afb1cde2072044d7d931c2f303032290c9
Status: Downloaded newer image for docker.io/gysan/dnsmasq-metrics-amd64:1.0
[root@kubernetes-master ~]# docker tag gysan/dnsmasq-metrics-amd64:1.0 gcr.io/google_containers/dnsmasq-metrics-amd64:1.0
[root@kubernetes-master ~]# docker pull warrior/k8s-dns-kube-dns-amd64:1.14.1
Trying to pull repository docker.io/warrior/k8s-dns-kube-dns-amd64 ... 
1.14.1: Pulling from docker.io/warrior/k8s-dns-kube-dns-amd64
e5e3de7014a6: Pull complete 
5e96979410c8: Pull complete 
Digest: sha256:f2d9698f64586b74e6eba4c423974101d5c34d10844a3f1e5e24716e0e6f3e6b
Status: Downloaded newer image for docker.io/warrior/k8s-dns-kube-dns-amd64:1.14.1
[root@kubernetes-master ~]# docker tag warrior/k8s-dns-kube-dns-amd64:1.14.1 gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.1
[root@kubernetes-master ~]# docker pull warrior/k8s-dns-dnsmasq-nanny-amd64:1.14.1
Trying to pull repository docker.io/warrior/k8s-dns-dnsmasq-nanny-amd64 ... 
1.14.1: Pulling from docker.io/warrior/k8s-dns-dnsmasq-nanny-amd64
d1426d011624: Pull complete 
b7721aa8d47c: Pull complete 
4a8eae141ba6: Pull complete 
d643c5d0fc0c: Pull complete 
7f3be923ec71: Pull complete 
Digest: sha256:1807899b0d07015d0b1e700d43859c657362b6455ff30bd7a3e14879afcc0ce3
Status: Downloaded newer image for docker.io/warrior/k8s-dns-dnsmasq-nanny-amd64:1.14.1
[root@kubernetes-master ~]# docker tag warrior/k8s-dns-dnsmasq-nanny-amd64:1.14.1 gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.1
[root@kubernetes-master ~]# docker pull warrior/k8s-dns-sidecar-amd64:1.14.1
Trying to pull repository docker.io/warrior/k8s-dns-sidecar-amd64 ... 
1.14.1: Pulling from docker.io/warrior/k8s-dns-sidecar-amd64
e5e3de7014a6: Already exists 
1fc5171ce36b: Pull complete 
Digest: sha256:20b89a3d369b119258a712e80cac62050ec41a6bdcb3ea1f31619747cdd7168f
Status: Downloaded newer image for docker.io/warrior/k8s-dns-sidecar-amd64:1.14.1
[root@kubernetes-master ~]# docker tag warrior/k8s-dns-sidecar-amd64:1.14.1 gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.1
[root@kubernetes-master ~]# docker pull awa305/kube-discovery-amd64:1.0
Trying to pull repository docker.io/awa305/kube-discovery-amd64 ... 
1.0: Pulling from docker.io/awa305/kube-discovery-amd64
627d84b6655e: Pull complete 
dddb11175374: Pull complete 
a3ed95caeb02: Pull complete 
Digest: sha256:7b725840d232709846b634e24bd481e7a045c03da65e89ca3705911e5be45b55
Status: Downloaded newer image for docker.io/awa305/kube-discovery-amd64:1.0
[root@kubernetes-master ~]# docker tag awa305/kube-discovery-amd64:1.0 gcr.io/google_containers/kube-discovery-amd64:1.0
[root@kubernetes-master ~]# docker pull gysan/exechealthz-amd64:1.2
Trying to pull repository docker.io/gysan/exechealthz-amd64 ... 
1.2: Pulling from docker.io/gysan/exechealthz-amd64
8ddc19f16526: Pull complete 
a3ed95caeb02: Pull complete 
7d1ee54af137: Pull complete 
476d09449781: Pull complete 
Digest: sha256:018e247cd52a6eb02c06e9c3e88534beb957e48f3d0b768df50de93943bfbac2
Status: Downloaded newer image for docker.io/gysan/exechealthz-amd64:1.2
[root@kubernetes-master ~]# docker tag gysan/exechealthz-amd64:1.2 gcr.io/google_containers/exechealthz-amd64:1.2
</code></pre>
<h3 id="3è¿è¡Œkubeadm-initå®‰è£…master">3.è¿è¡Œkubeadm initå®‰è£…Master</h3>
<p>å‡†å¤‡å·¥ä½œå°±ç»ªï¼Œæ‰§è¡Œkubeadm initå‘½ä»¤å³å¯ä¸€é”®å®ŒæˆKubernetes MasterèŠ‚ç‚¹çš„å®‰è£…</p>
<pre><code># kubeadm init --kubernetes-version=1.15.1      
[ERROR ImagePull]: failed to pull image k8s.gcr.io/kube-controller-manager:v1.15.2: output: Trying to pull repository k8s.gcr.io/kube-controller-manager ... 
Get https://k8s.gcr.io/v1/_ping: dial tcp 64.233.189.82:443: i/o timeout

# cat kubernetes.sh                 å¦‚æœå‡ºç°ä»¥ä¸Šé”™è¯¯ï¼Œåˆ™éœ€è¦æ‰‹åŠ¨ç¼–å†™è„šæœ¬æ‹‰å–é•œåƒç„¶åå†æ‰§è¡Œkubeadm init
docker pull mirrorgooglecontainers/kube-apiserver:v1.15.1
docker pull mirrorgooglecontainers/kube-controller-manager:v1.15.1
docker pull mirrorgooglecontainers/kube-scheduler:v1.15.1
docker pull mirrorgooglecontainers/kube-proxy:v1.15.1
docker pull mirrorgooglecontainers/pause:3.1
docker pull mirrorgooglecontainers/etcd:3.3.10
docker pull coredns/coredns:1.3.1

docker tag mirrorgooglecontainers/kube-proxy:v1.15.1  k8s.gcr.io/kube-proxy:v1.15.1
docker tag mirrorgooglecontainers/kube-scheduler:v1.15.1 k8s.gcr.io/kube-scheduler:v1.15.1
docker tag mirrorgooglecontainers/kube-apiserver:v1.15.1 k8s.gcr.io/kube-apiserver:v1.15.1
docker tag mirrorgooglecontainers/kube-controller-manager:v1.15.1 k8s.gcr.io/kube-controller-manager:v1.15.1
docker tag mirrorgooglecontainers/etcd:3.3.10  k8s.gcr.io/etcd:3.3.10
docker tag coredns/coredns:1.3.1 k8s.gcr.io/coredns:1.3.1
docker tag mirrorgooglecontainers/pause:3.1  k8s.gcr.io/pause:3.1


docker rmi mirrorgooglecontainers/kube-apiserver:v1.15.1
docker rmi mirrorgooglecontainers/kube-controller-manager:v1.15.1
docker rmi mirrorgooglecontainers/kube-scheduler:v1.15.1
docker rmi mirrorgooglecontainers/kube-proxy:v1.15.1
docker rmi mirrorgooglecontainers/pause:3.1
docker rmi mirrorgooglecontainers/etcd:3.3.10
docker rmi coredns/coredns:1.3.1
# bash kubernetes.sh
# kubeadm init --kubernetes-version=1.15.1      å‡ºç°ä»¥ä¸‹ç»“æœï¼Œè¡¨ç¤ºå®‰è£…æˆåŠŸ
Your Kubernetes control-plane has initialized successfully!
......
kubeadm join 172.16.31.105:6443 --token tbjzb3.834myq2mm0g7aewm \
    --discovery-token-ca-cert-hash sha256:f0cecec6a64fa51d533abc64db1207d4d8d6c626445c233a66800b4d79222e33 

</code></pre>
<h3 id="4å®‰è£…nodeåŠ å…¥é›†ç¾¤">4.å®‰è£…Nodeï¼ŒåŠ å…¥é›†ç¾¤</h3>
<p>åœ¨æ–°çš„èŠ‚ç‚¹å®‰è£…kubeadmå’Œç›¸å…³å·¥å…·</p>
<pre><code># yum install -y docker kubelet kubeadm kubectl kubernetes-cni
# systemctl enable docker &amp;&amp; systemctl start docker 
# systemctl enable kubelet &amp;&amp; systemctl start kubelet
</code></pre>
<p>æ‰§è¡Œkubeadm joinå‘½ä»¤åŠ å…¥é›†ç¾¤ï¼š</p>
<pre><code># kubeadm join --token tbjzb3.834myq2mm0g7aewm 172.16.31.105:6443
</code></pre>
<p>å…¶ä¸­tokençš„å€¼æ¥è‡ªä½¿ç”¨kubeadmå®‰è£…Masterè¿‡ç¨‹ä¸­æç¤ºçš„æœ€åä¸€è¡Œæä¾›çš„tokenï¼Œ172.16.31.105:6443æ˜¯Masterçš„ipå’Œç«¯å£åœ°å€ã€‚é»˜è®¤æƒ…å†µä¸‹MasterèŠ‚ç‚¹ä¸å‚ä¸å·¥ä½œè´Ÿè½½ï¼Œå¦‚æœå¸Œæœ›MasterèŠ‚ç‚¹æˆä¸ºä¸€ä¸ªNodeèŠ‚ç‚¹ï¼š</p>
<pre><code># kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre>
<h3 id="5å®‰è£…ç½‘ç»œæ’ä»¶">5.å®‰è£…ç½‘ç»œæ’ä»¶</h3>
<p>é€šè¿‡kubectl get nodeså‘½ä»¤ï¼Œå‘ç°Kubernetesæç¤ºMasterèŠ‚ç‚¹ä¸ºNotReadyçŠ¶æ€ï¼Œè¿™æ˜¯å› ä¸ºè¿˜æ²¡æœ‰å®‰è£…CNIç½‘ç»œæ’ä»¶ï¼š</p>
<pre><code>[root@kubernetes-master ~]# kubectl get nodes
NAME                STATUS     ROLES    AGE   VERSION
kubernetes-master   NotReady   master   26m   v1.15.1
</code></pre>
<p>å®‰è£…weaveç½‘ç»œæ’ä»¶ï¼š</p>
<pre><code># kubectl apply -f https://git.io/weave-kube-1.6
</code></pre>
<h3 id="6éªŒè¯kubernetesé›†ç¾¤å®‰è£…å®Œæˆ">6.éªŒè¯Kubernetesé›†ç¾¤å®‰è£…å®Œæˆ</h3>
<p>æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤ï¼ŒéªŒè¯Kubernetesé›†ç¾¤çš„ç›¸å…³Podæ˜¯å¦éƒ½æ­£å¸¸åˆ›å»ºå¹¶è¿è¡Œï¼š</p>
<pre><code>[root@kubernetes-master ~]# kubectl get pods --all-namespaces
NAMESPACE     NAME                                        READY   STATUS    RESTARTS   AGE
kube-system   coredns-5c98db65d4-c7kwc                    1/1     Running   0          31m
kube-system   coredns-5c98db65d4-h998m                    1/1     Running   0          31m
kube-system   etcd-kubernetes-master                      1/1     Running   0          30m
kube-system   kube-apiserver-kubernetes-master            1/1     Running   0          30m
kube-system   kube-controller-manager-kubernetes-master   1/1     Running   0          30m
kube-system   kube-proxy-58jhz                            1/1     Running   0          31m
kube-system   kube-scheduler-kubernetes-master            1/1     Running   0          30m
kube-system   weave-net-plfgc                             2/2     Running   0          96s
</code></pre>
<p>è‡³æ­¤ï¼Œé€šè¿‡kubeadmå·¥å…·å°±å®ç°äº†Kubernetesé›†ç¾¤çš„å¿«é€Ÿæ­å»ºï¼Œå¦‚æœå®‰è£…å¤±è´¥ï¼Œå¯ä»¥æ‰§è¡Œkubeadm resetå‘½ä»¤å°†ä¸»æœºæ¢å¤åŸçŠ¶ã€‚</p>
<h2 id="ä»¥äºŒè¿›åˆ¶æ–‡ä»¶æ–¹å¼å®‰è£…kubernetesé›†ç¾¤">ä»¥äºŒè¿›åˆ¶æ–‡ä»¶æ–¹å¼å®‰è£…Kubernetesé›†ç¾¤</h2>
<p>ä¸‹è½½å‹ç¼©åŒ…ï¼š</p>
<pre><code>[root@kubernetes-master ~]# wget https://github.com/kubernetes/kubernetes/archive/v1.15.2.tar.gz
</code></pre>
<h2 id="kubectlå‘½ä»¤è¡Œç”¨æ³•">Kubectlå‘½ä»¤è¡Œç”¨æ³•</h2>
<p>kubectlä½œä¸ºå®¢æˆ·ç«¯cliå·¥å…·ï¼Œå¯ä»¥è®©ç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œçš„æ–¹å¼å¯¹Kubernetesé›†ç¾¤è¿›è¡Œæ“ä½œã€‚</p>
<h3 id="kubectlç”¨æ³•æ¦‚è¿°">kubectlç”¨æ³•æ¦‚è¿°</h3>
<p>kubectlå‘½ä»¤è¡Œçš„è¯­æ³•å¦‚ä¸‹ï¼š</p>
<pre><code># kubectl [command] [TYPE] [NAME] [flags]
1.commandï¼šå­å‘½ä»¤ï¼Œç”¨äºæ“ä½œKubernetesé›†ç¾¤èµ„æºå¯¹è±¡çš„å‘½ä»¤ï¼Œä¾‹å¦‚createã€deleteã€describeã€getã€applyç­‰ã€‚
2.TYPEï¼šèµ„æºå¯¹è±¡çš„ç±»å‹ï¼ŒåŒºåˆ†å¤§å°å†™ï¼Œèƒ½ä»¥å•æ•°å½¢å¼ã€å¤æ•°å½¢å¼æˆ–è€…ç®€å†™å½¢å¼è¡¨ç¤ºã€‚
3.NAMEï¼šèµ„æºå¯¹è±¡çš„åç§°ï¼ŒåŒºåˆ†å¤§å°å†™ï¼Œå¦‚æœä¸æŒ‡å®šåç§°ï¼Œåˆ™ç³»ç»Ÿå°†è¿”å›å±äºTYPEçš„å…¨éƒ¨å¯¹è±¡çš„åˆ—è¡¨ï¼Œä¾‹å¦‚# kubectl get podså°†è¿”å›æ‰€æœ‰Podçš„åˆ—è¡¨ã€‚
4.flagsï¼škubectlå­å‘½ä»¤çš„å¯é€‰å‚æ•°ï¼Œä¾‹å¦‚ä½¿ç”¨â€œ-sâ€æŒ‡å®šapiserverçš„URLåœ°å€è€Œä¸ç”¨é»˜è®¤å€¼ã€‚
</code></pre>
<h3 id="æ“ä½œç¤ºä¾‹">æ“ä½œç¤ºä¾‹</h3>
<h4 id="1åˆ›å»ºèµ„æºå¯¹è±¡">1.åˆ›å»ºèµ„æºå¯¹è±¡</h4>
<p>æ ¹æ®yamlé…ç½®æ–‡ä»¶ä¸€æ¬¡æ€§åˆ›å»ºserviceå’Œrcï¼š</p>
<pre><code># kubectl create -f my-service.yaml -f my-rc.yaml
</code></pre>
<p>æ ¹æ®<directory>ç›®å½•ä¸‹æ‰€æœ‰.yamlã€.ymlã€.jsonæ–‡ä»¶çš„å®šä¹‰è¿›è¡Œåˆ›å»ºæ“ä½œï¼š</p>
<pre><code># kubectl create -f &lt;directory&gt;
</code></pre>
<h4 id="2æŸ¥çœ‹èµ„æºå¯¹è±¡">2.æŸ¥çœ‹èµ„æºå¯¹è±¡</h4>
<p>æŸ¥çœ‹æ‰€æœ‰Podåˆ—è¡¨ï¼š</p>
<pre><code># kubectl get pods
</code></pre>
<p>æŸ¥çœ‹rcå’Œserviceåˆ—è¡¨ï¼š</p>
<pre><code>kubectl get rc,service
</code></pre>
<h4 id="3æè¿°èµ„æºå¯¹è±¡">3.æè¿°èµ„æºå¯¹è±¡</h4>
<p>æŸ¥çœ‹Nodeçš„è¯¦ç»†ä¿¡æ¯ï¼š</p>
<pre><code># kubectl describe nodes &lt;node-name&gt;
</code></pre>
<p>æ˜¾ç¤ºPodçš„è¯¦ç»†ä¿¡æ¯ï¼š</p>
<pre><code># kubectl describe pods/&lt;pod-name&gt;
</code></pre>
<p>æ˜¾ç¤ºç”±RCç®¡ç†çš„Podä¿¡æ¯ï¼š</p>
<pre><code># kubectl describe pods &lt;rc-name&gt;
</code></pre>
<h4 id="4åˆ é™¤èµ„æºå¯¹è±¡">4.åˆ é™¤èµ„æºå¯¹è±¡</h4>
<p>åŸºäºpod.yamlå®šä¹‰çš„åç§°åˆ é™¤Podï¼š</p>
<pre><code># kubectl delete -f pod.yaml
</code></pre>
<p>åˆ é™¤æ‰€æœ‰åŒ…å«æŸä¸ªlabelçš„Podå’Œserviceï¼š</p>
<pre><code># kubectl delete pods,services -l name=&lt;label-name&gt;
</code></pre>
<p>åˆ é™¤æ‰€æœ‰Podï¼š</p>
<pre><code># kubectl delete pods --all
</code></pre>
<h4 id="5æ‰§è¡Œå®¹å™¨çš„å‘½ä»¤">5.æ‰§è¡Œå®¹å™¨çš„å‘½ä»¤</h4>
<p>æ‰§è¡ŒPodçš„dateå‘½ä»¤ï¼Œé»˜è®¤ä½¿ç”¨Podä¸­çš„ç¬¬1ä¸ªå®¹å™¨æ‰§è¡Œï¼š</p>
<pre><code># kubectl exec &lt;pod-name&gt; date
</code></pre>
<p>æŒ‡å®šPodä¸­æŸä¸ªå®¹å™¨æ‰§è¡Œdateå‘½ä»¤ï¼š</p>
<pre><code># kubectl exec &lt;pod-name&gt; -c &lt;container-name&gt; date
</code></pre>
<p>é€šè¿‡bashè·å¾—Podä¸­æŸä¸ªå®¹å™¨çš„TTYï¼Œç›¸å½“äºç™»å½•å®¹å™¨ï¼š</p>
<pre><code># kubectl exec -ti &lt;pod-name&gt; -c &lt;container-name&gt; /bin/bash
</code></pre>
<h4 id="6æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—">6.æŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—</h4>
<p>æŸ¥çœ‹å®¹å™¨è¾“å‡ºåˆ°stdoutçš„æ—¥å¿—ï¼š</p>
<pre><code># kubectl logs &lt;pod-name&gt;
</code></pre>
<p>è·Ÿè¸ªæŸ¥çœ‹å®¹å™¨çš„æ—¥å¿—ï¼Œç›¸å½“äºtail -få‘½ä»¤çš„ç»“æœï¼š</p>
<pre><code># kubectl logs -f &lt;pod-name&gt; -c &lt;container-name&gt;
</code></pre>
<h2 id="æ·±å…¥æŒæ¡pod">æ·±å…¥æŒæ¡Pod</h2>
<h3 id="podå®šä¹‰è¯¦æƒ…">Podå®šä¹‰è¯¦æƒ…</h3>
<p>yamlæ ¼å¼çš„Podå®šä¹‰æ–‡ä»¶çš„å®Œæ•´å†…å®¹å¦‚ä¸‹ï¼š</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: string
  namespace: string
  labels:
    - name: stirng
  annotations:
    - name: string
spec:
  containers:
  - name: string
    image: string
    imagePullPolicy: [Always | Never | IfNotPresent]
    command: [string]
    args: [string]
    workingDir: string
    volumeMounts:
    - name: string
      mountPath: string
      readOnly: boolean
    ports:
    - name: string
      containerPort: int
      hostPort: int
      protocol: string
    env:
    - name: string
      value: string
    resources:
      limits:
        cpu: string
        memory: string
      requests:
        cpu: string
        memory: string
    livenessProbe:
      exec:
        command: [string]
      httpGet:
        path: string
        port: number
        host: string
        scheme: string
        httpHeaders:
        - name: string
          value: string
      tcpSocket:
        port: number
      initialDelaySeconds: 0
      timeoutSeconds: 0
      periodSeconds: 0
      successThreshold: 0
      failureThreshold: 0
    securityContext:
      privileged: false
  restartPolicy: [Always | Never | OnFailure]
  nodeSelector: object
  imagePullSecrets:
  - name: string
  hostNetwork: false
  volumes:
  - name: string
    emptyDir: {}
    hostPath:
      path: string
    secret:
      secretName: string
      items:
      - key: string
        path: string
    configMap:
      name: string
      items:
      - key: string
        path: string
</code></pre>
<h2 id="æ·±å…¥æŒæ¡service">æ·±å…¥æŒæ¡Service</h2>
<h1 id="kubernetesæ ¸å¿ƒåŸç†">Kubernetesæ ¸å¿ƒåŸç†</h1>
<p>Kubernetes API Serverçš„æ ¸å¿ƒåŠŸèƒ½æ˜¯æä¾›äº†Kuberneteså„ç±»èµ„æºå¯¹è±¡ï¼ˆPodã€RCã€Serviceç­‰ï¼‰çš„å¢ã€åˆ ã€æ”¹ã€æŸ¥åŠWatchç­‰HTTP Restæ¥å£ï¼Œæˆä¸ºé›†ç¾¤å†…å„ä¸ªåŠŸèƒ½æ¨¡å—ç›´æ¥æ•°æ®äº¤äº’å’Œé€šä¿¡çš„ä¸­å¿ƒæ¢çº½ã€‚</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea Demo]]></title>
        <id>https://liuhuipy.github.io/post/hello-gridea/</id>
        <link href="https://liuhuipy.github.io/post/hello-gridea/">
        </link>
        <updated>2019-01-11T16:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Gridea</strong> ï¼<br>
âœï¸  <strong>Gridea</strong> ä¸€ä¸ªé™æ€åšå®¢å†™ä½œå®¢æˆ·ç«¯ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥è®°å½•ä½ çš„ç”Ÿæ´»ã€å¿ƒæƒ…ã€çŸ¥è¯†ã€ç¬”è®°ã€åˆ›æ„... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>ğŸ‘  æ¬¢è¿ä½¿ç”¨ <strong>Gridea</strong> ï¼<br>
âœï¸  <strong>Gridea</strong> ä¸€ä¸ªé™æ€åšå®¢å†™ä½œå®¢æˆ·ç«¯ã€‚ä½ å¯ä»¥ç”¨å®ƒæ¥è®°å½•ä½ çš„ç”Ÿæ´»ã€å¿ƒæƒ…ã€çŸ¥è¯†ã€ç¬”è®°ã€åˆ›æ„... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea ä¸»é¡µ</a><br>
<a href="http://fehey.com/">ç¤ºä¾‹ç½‘ç«™</a></p>
<h2 id="ç‰¹æ€§">ç‰¹æ€§ğŸ‘‡</h2>
<p>ğŸ“  ä½ å¯ä»¥ä½¿ç”¨æœ€é…·çš„ <strong>Markdown</strong> è¯­æ³•ï¼Œè¿›è¡Œå¿«é€Ÿåˆ›ä½œ</p>
<p>ğŸŒ‰  ä½ å¯ä»¥ç»™æ–‡ç« é…ä¸Šç²¾ç¾çš„å°é¢å›¾å’Œåœ¨æ–‡ç« ä»»æ„ä½ç½®æ’å…¥å›¾ç‰‡</p>
<p>ğŸ·ï¸  ä½ å¯ä»¥å¯¹æ–‡ç« è¿›è¡Œæ ‡ç­¾åˆ†ç»„</p>
<p>ğŸ“‹  ä½ å¯ä»¥è‡ªå®šä¹‰èœå•ï¼Œç”šè‡³å¯ä»¥åˆ›å»ºå¤–éƒ¨é“¾æ¥èœå•</p>
<p>ğŸ’»  ä½ å¯ä»¥åœ¨ <strong>Windows</strong>ï¼Œ<strong>MacOS</strong> æˆ– <strong>Linux</strong> è®¾å¤‡ä¸Šä½¿ç”¨æ­¤å®¢æˆ·ç«¯</p>
<p>ğŸŒ  ä½ å¯ä»¥ä½¿ç”¨ <strong>ğ–¦ğ—‚ğ—ğ—ğ—ğ–» ğ–¯ğ–ºğ—€ğ–¾ğ—Œ</strong> æˆ– <strong>Coding Pages</strong> å‘ä¸–ç•Œå±•ç¤ºï¼Œæœªæ¥å°†æ”¯æŒæ›´å¤šå¹³å°</p>
<p>ğŸ’¬  ä½ å¯ä»¥è¿›è¡Œç®€å•çš„é…ç½®ï¼Œæ¥å…¥ <a href="https://github.com/gitalk/gitalk">Gitalk</a> æˆ– <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> è¯„è®ºç³»ç»Ÿ</p>
<p>ğŸ‡¬ğŸ‡§  ä½ å¯ä»¥ä½¿ç”¨<strong>ä¸­æ–‡ç®€ä½“</strong>æˆ–<strong>è‹±è¯­</strong></p>
<p>ğŸŒ  ä½ å¯ä»¥ä»»æ„ä½¿ç”¨åº”ç”¨å†…é»˜è®¤ä¸»é¢˜æˆ–ä»»æ„ç¬¬ä¸‰æ–¹ä¸»é¢˜ï¼Œå¼ºå¤§çš„ä¸»é¢˜è‡ªå®šä¹‰èƒ½åŠ›</p>
<p>ğŸ–¥  ä½ å¯ä»¥è‡ªå®šä¹‰æºæ–‡ä»¶å¤¹ï¼Œåˆ©ç”¨ OneDriveã€ç™¾åº¦ç½‘ç›˜ã€iCloudã€Dropbox ç­‰è¿›è¡Œå¤šè®¾å¤‡åŒæ­¥</p>
<p>ğŸŒ± å½“ç„¶ <strong>Gridea</strong> è¿˜å¾ˆå¹´è½»ï¼Œæœ‰å¾ˆå¤šä¸è¶³ï¼Œä½†è¯·ç›¸ä¿¡ï¼Œå®ƒä¼šä¸åœå‘å‰ ğŸƒ</p>
<p>æœªæ¥ï¼Œå®ƒä¸€å®šä¼šæˆä¸ºä½ ç¦»ä¸å¼€çš„ä¼™ä¼´</p>
<p>å°½æƒ…å‘æŒ¥ä½ çš„æ‰åå§ï¼</p>
<p>ğŸ˜˜ Enjoy~</p>
]]></content>
    </entry>
</feed>